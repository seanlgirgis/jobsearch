# Tailored Resume Preview

**Sean Luka Girgis**  
Senior Data Engineer | Capacity Planning & AI-Driven Infrastructure Optimization  
214-315-2190 | seanlgirgis@gmail.com  
[LinkedIn](https://www.linkedin.com/in/sean-girgis-43bb1b5/) | [GitHub](https://github.com/seanlgirgis) | [Portfolio](https://seanlgirgis.github.io)  

## Professional Summary
Senior Data Engineer with over 20 years of enterprise experience, specializing in Machine Learning, AI, and distributed data processing systems like Apache Spark and PySpark for real-time data processing and process optimization. Proficient in Python programming, I have a proven track record of building ML pipelines for forecasting and anomaly detection. Experienced in deploying scalable data solutions and collaborating with cross-functional teams for product deployment. Passionate about driving innovation in manufacturing AI, I am eager to contribute to Oden Technologies’ mission of enhancing factory operations through advanced algorithms. My expertise in timeseries analysis and data engineering aligns with creating impactful solutions for manufacturing processes. I thrive in environments focused on customer success collaboration and delivering next-generation product features.

## Professional Experience
### Senior Capacity & Data Engineer at CITI
2017-11 – 2025-12
- Architected automated ETL pipelines using Python and Pandas to ingest high-scale telemetry data, enhancing real-time data processing capabilities.
- Developed ML forecasting models with Prophet and scikit-learn for capacity bottleneck prediction, improving provisioning accuracy by anticipating issues 6 months ahead.
- Designed optimized Oracle schemas for historical data retention, supporting timeseries analysis and seasonal risk forecasting.
- Integrated disparate data feeds into unified reporting systems with executive dashboards, enabling process optimization and anomaly detection.
- Applied statistical analysis and machine learning to identify underutilized infrastructure, driving significant cost savings through hardware consolidation.
- Automated reporting workflows with Python scripts, streamlining data preparation and monitoring processes for enterprise-scale systems.

### Performance Engineer at G6 Hospitality LLC
2017-03 – 2017-11
- Managed Dynatrace AppMon/Synthetics for critical systems, focusing on real-time performance monitoring and alerting.
- Led 'FAST' project to data-mine user performance metrics, providing optimization recommendations for key revenue-generating systems.
- Upgraded Dynatrace infrastructure (6.5 to 7.0) and supported cloud migration to AWS, ensuring robust end-to-end monitoring.
- Analyzed system bottlenecks and suggested performance improvements, contributing to process optimization.
- Provided detailed dashboarding for before/after metrics, supporting data-driven decision-making.
- Integrated Performance Center with Dynatrace for comprehensive performance insights.

### Senior Consultant / SME for CA APM at CA Technologies (various clients) & Enterprise Iron (TIAA-CREF)
2011 – 2016
- Led large-scale CA APM implementations and upgrades (9.1 to 10.1), managing 4,000–6,000 agents for enterprise systems.
- Designed custom Management Modules, dashboards, and alerts to support real-time monitoring and anomaly detection.
- Developed Perl/Ksh scripts for data extraction, automating reporting and data preparation processes.
- Provided sizing recommendations and bottleneck resolution for J2EE/.NET environments, enhancing system performance.
- Trained client teams on APM solutions, fostering effective customer success collaboration.
- Collaborated with IT teams to troubleshoot performance issues, ensuring optimal system deployment.

### Performance Test Engineer at AT&T
2010-08 – 2011-07
- Analyzed J2EE telecom applications to identify load and resource bottlenecks, focusing on performance optimization.
- Documented critical metrics including JDBC connections, threads, memory, CPU, and garbage collection for system monitoring.
- Installed JMX, Thread Dumps, and Wily Introscope to enhance real-time data processing and monitoring.
- Created automation scripts to streamline performance testing and reporting workflows.

### Senior Systems & Data Migration Engineer at Sabre
2008-05 – 2012
- Led massive data migration of a high-throughput shopping engine from 200+ MySQL nodes to a 6-node Oracle RAC cluster.
- Optimized core transaction processing using C++ and OCCI, reducing hardware footprint by 95% while maintaining sub-second latency.
- Built a CPPUNIT testing framework to automate conversion and validation processes.
- Ensured high-performance data processing for a system handling 10x the throughput of VISA.
- Collaborated with engineering teams for seamless deployment of optimized solutions.
- Focused on process optimization to achieve significant infrastructure efficiency gains.

## Education
**High Diploma / Post-Graduate Diploma in Computer Engineering Technology / Computer Science**  
Humber College, Toronto, Canada

**Bachelor of Science in Civil Engineering**  
Zagazig University, Egypt / Cairo, Egypt

## Skills
Python (15 years, Expert), Machine Learning (Advanced), PySpark (6 years, Advanced), Distributed Data Processing (Advanced), ML Workflows (Advanced), SQL / Oracle (18 years, Expert), Generative AI (2 years, Intermediate-Advanced), GCP (Advanced), Prophet / Time-Series Forecasting (5 years, Advanced), scikit-learn (6 years, Advanced), AWS (7 years, Advanced), Pandas (10 years, Expert), ETL Design & Optimization (15 years, Expert), Data Warehousing (10 years, Advanced), Streamlit (3 years, Advanced), Hive/Hadoop (7 years, Advanced), Airflow (5 years, Advanced), Capacity Planning / Forecasting (15 years, Expert), GenAI / LLM Agents (2 years, Intermediate-Advanced), C++ (20 years, Expert), Java (10 years, Advanced), Perl (12 years, Advanced), Ksh / Korn Shell Scripting (12 years, Advanced), PL/SQL (18 years, Expert), Dynatrace (AppMon + Synthetics) (8 years, Expert), CA APM / Introscope (10 years, Expert), BMC TrueSight / TSCO (7 years, Advanced), Oracle RAC (10 years, Advanced), Multiprocessing (10 years, Advanced), Docker (5 years, Advanced), Git (10 years, Advanced), Linux/Unix (20 years, Expert), OCCI / OCI (10 years, Advanced), WebLogic / WebSphere (10 years, Advanced), VB6 / VC++ (5 years, Intermediate)

## Flagship Projects
### Serverless Lakehouse Platform (AWS)
Designed a full serverless data platform using S3, Glue, Athena, and Bedrock. Built a Text-to-SQL GenAI agent with Claude 3 Sonnet for enhanced querying. Resolved small file issues with Snappy and Parquet compression. Optimized ETL processes and data access for enterprise-scale operations.
**Technologies:** AWS Glue, Athena, Bedrock (GenAI), S3, PySpark

### HorizonScale — AI Capacity Forecasting Engine
Replaced legacy manual processes with a parallel generator-based pipeline, reducing forecasting cycles by 90%. Developed an interactive Streamlit dashboard for real-time capacity insights and 'High Trust' utilization scores. Created a modern agentic pipeline for banking-scale telemetry. Features comprehensive documentation, API guides, and performance benchmarks.
**Technologies:** Python, Prophet, Streamlit, PySpark, Multiprocessing, Spark, Machine Learning, Data Pipelines, API Integration, Performance Benchmarking, Testing and Validation, AI Reasoning, RAG (Retrieval-Augmented Generation)
**Repo:** [github.com/seanlgirgis/HorizonStudy](https://github.com/seanlgirgis/HorizonStudy)

### FAST Project
Conducted data mining on user performance metrics to optimize critical money-generating systems. Focused on identifying bottlenecks and enhancing system efficiency.
**Technologies:** Dynatrace, Data Mining

