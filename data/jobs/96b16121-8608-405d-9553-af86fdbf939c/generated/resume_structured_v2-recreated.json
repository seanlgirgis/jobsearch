{
  "personal": {
    "full_name": "Sean Luka Girgis",
    "preferred_title": "Senior Data Engineer | Data Pipeline & Warehouse Modeling Specialist",
    "phone": "214-315-2190",
    "email": "seanlgirgis@gmail.com",
    "location_preference": "Plano, TX / Dallas-Fort Worth / Remote",
    "portfolio_url": "https://seanlgirgis.github.io",
    "linkedin": "https://www.linkedin.com/in/sean-girgis-43bb1b5/",
    "github": "https://github.com/seanlgirgis",
    "x_twitter": "https://x.com/SeanLuka22249",
    "target_roles": [
      "Senior Data Engineer",
      "AI Engineer",
      "Cloud Data Architect",
      "Capacity Planning Engineer",
      "PySpark / AWS Specialist"
    ]
  },
  "summary": "Senior Data Engineer with over 20 years of enterprise experience in designing and optimizing data pipelines and warehouse models. Expert in building scalable ELT workflows, dimensional modeling, and data governance using Python, SQL, and AWS technologies like Glue and Athena. Proficient in orchestration tools and modern data platforms, delivering analytics-ready datasets for business insights. Specialized in transforming raw data into trusted models for reporting and data science. Collaborative technical leader adept at mentoring teams and driving operational reliability.",
  "flagship_projects": [
    {
      "name": "Serverless Lakehouse Platform (AWS)",
      "tech": [
        "AWS Glue",
        "Athena",
        "Bedrock (GenAI)",
        "S3",
        "PySpark"
      ],
      "description": "Architected a comprehensive serverless data platform to streamline data ingestion and transformation. Engineered a Text-to-SQL GenAI agent with Claude 3 Sonnet for enhanced query capabilities. Addressed small-file challenges by implementing Snappy Parquet compression, optimizing storage and performance."
    },
    {
      "name": "HorizonScale — AI Capacity Forecasting Engine",
      "tech": [
        "Python",
        "Prophet",
        "Streamlit",
        "PySpark",
        "Multiprocessing"
      ],
      "description": "Developed an advanced AI-driven forecasting engine to replace outdated manual Trenda processes. Implemented a parallel generator-based pipeline, slashing forecasting cycles by 90%. Created an interactive Streamlit dashboard for real-time capacity insights and 'High Trust' utilization metrics."
    }
  ],
  "experience": [
    {
      "company": "CITI",
      "title": "Senior Capacity & Data Engineer",
      "start_date": "2017-11",
      "end_date": "2025-12",
      "bullets": [
        "Architected automated ELT pipelines using Python and Pandas to ingest P95 performance telemetry from over 6,000 endpoints (BMC TrueSight/TSCO), eliminating manual processes.",
        "Designed optimized Oracle Database schemas for historical data retention, supporting long-term trend analysis and seasonal risk forecasting.",
        "Built ML-driven forecasting models with Prophet and scikit-learn to predict infrastructure bottlenecks up to 6 months ahead.",
        "Unified disparate data sources (CSV, Excel, TSCO) into a cohesive Oracle reporting framework, enabling executive-level dashboards for strategic insights."
      ]
    },
    {
      "company": "G6 Hospitality LLC",
      "title": "Performance Engineer",
      "start_date": "2017-03",
      "end_date": "2017-11",
      "bullets": [
        "Managed comprehensive monitoring solutions using Dynatrace AppMon and Synthetics to ensure system reliability.",
        "Spearheaded the 'FAST' project, leveraging data mining to enhance user performance metrics for revenue-critical systems.",
        "Facilitated AWS cloud migration efforts and evaluated mobile monitoring tools to support scalability."
      ]
    },
    {
      "company": "CA Technologies / TIAA-CREF / Enterprise Iron",
      "title": "Senior Consultant & CA APM SME",
      "start_date": "2011",
      "end_date": "2017",
      "bullets": [
        "Directed enterprise-wide CA APM implementations and upgrades (v9.1 → v10.1) across 4,000–6,000 agents, ensuring seamless transitions.",
        "Developed custom dashboards, alerts, reports, and Perl/Ksh scripts, alongside tailored Management Modules for enhanced monitoring.",
        "Provided expert architectural sizing and troubleshooting for J2EE/.NET environments, optimizing performance and reliability."
      ]
    },
    {
      "company": "Sabre",
      "title": "Senior Systems & Data Migration Engineer",
      "start_date": "2008",
      "end_date": "2012",
      "bullets": [
        "Led large-scale data migration to a 6-node Oracle RAC cluster, handling throughput 10x that of VISA transactions.",
        "Optimized transaction processing using C++ and OCCI, achieving a 95% reduction in hardware footprint with sub-second latency."
      ]
    }
  ],
  "skills": [
    "SQL / Oracle (Expert, 18 years)",
    "Python (Expert, 15 years)",
    "PySpark (Advanced, 6 years)",
    "AWS (Advanced, 7 years)",
    "Prophet / Time-Series Forecasting (Advanced, 5 years)",
    "GenAI / LLM Agents (Intermediate-Advanced, 2 years)"
  ],
  "education": [
    {
      "degree": "Post-Graduate Diploma in Computer Science",
      "institution": "Humber College",
      "location": "Canada"
    },
    {
      "degree": "Bachelor of Science in Civil Engineering",
      "institution": "Zagazig University",
      "location": "Egypt"
    }
  ]
}