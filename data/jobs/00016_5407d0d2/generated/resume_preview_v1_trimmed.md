# Tailored Resume Preview

**Sean Luka Girgis**  
Senior Data Engineer | Capacity Planning & AI-Driven Infrastructure Optimization  
214-315-2190 | seanlgirgis@gmail.com  
[LinkedIn](https://www.linkedin.com/in/sean-girgis-43bb1b5/) | [GitHub](https://github.com/seanlgirgis) | [Portfolio](https://seanlgirgis.github.io)  

## Professional Summary
Senior Data Engineer with over 20 years of enterprise experience, specializing in architecting scalable data pipelines and AI-driven solutions for high-performance systems. Proficient in Python, SQL, PySpark, and cloud platforms like AWS, I excel in translating complex Data & AI use-case requirements into effective data models and pipelines. My expertise includes performance optimization, cloud deployment, and software engineering best practices for building scalable solutions. I have a proven track record in leveraging Spark and Databricks to transform data into actionable insights. I am passionate about contributing to AT&T's mission of driving innovation through advanced data and AI applications. I am eager to lead impactful projects in Dallas, TX, ensuring data integrity and scalability.

## Professional Experience
### Senior Capacity & Data Engineer at CITI
2017-11 – 2025-12
- Architected automated ETL pipelines using Python and Pandas to ingest P95 telemetry from 6,000+ endpoints, enhancing data models for scalability.
- Developed ML forecasting models with Prophet and scikit-learn to predict bottlenecks 6 months ahead, optimizing performance and provisioning accuracy.
- Designed optimized Oracle schemas for historical data retention, supporting seasonal risk forecasting and data integrity.
- Integrated disparate data feeds into unified Oracle reporting systems, creating executive dashboards for actionable insights.
- Applied statistical analysis and data mining to identify underutilized infrastructure, driving cost optimization through hardware consolidation.
- Built automated reporting workflows and interactive dashboards using Python libraries like matplotlib and plotly for real-time insights.

### Performance Engineer at G6 Hospitality LLC
2017-03 – 2017-11
- Managed Dynatrace AppMon/Synthetics for critical systems, ensuring performance monitoring and data integrity.
- Led 'FAST' project to data-mine real-user performance metrics, providing optimization recommendations for key systems.
- Upgraded Dynatrace from 6.5 to 7.0, implemented TLS1.2 security, and supported cloud migration to AWS.
- Developed dashboards for end-to-end functionality, delivering before/after metrics for performance evaluation.
- Analyzed system bottlenecks and proposed actionable performance improvements.
- Integrated Performance Center with Dynatrace for comprehensive monitoring solutions.

### Senior Consultant / SME for CA APM at CA Technologies (various clients) & Enterprise Iron (TIAA-CREF)
2011 – 2016
- Led large-scale CA APM implementations and upgrades (9.1 to 10.1), managing 4,000–6,000 agents for enterprise systems.
- Designed custom Management Modules, dashboards, and alerts, enhancing performance monitoring capabilities.
- Developed Perl and Ksh scripts for data extraction, supporting data pipelines and reporting.
- Provided sizing recommendations and Golden Images for deployments, ensuring scalability and efficiency.
- Trained client teams and resolved performance bottlenecks in J2EE and .NET environments.
- Collaborated with IT teams to troubleshoot and optimize system performance for large-scale deployments.

### Performance Test Engineer at AT&T
2010-08 – 2011-07
- Analyzed J2EE telecom applications to identify load and break points, ensuring performance optimization.
- Documented critical metrics including JDBC connections, threads, memory, CPU, and GC for system reliability.
- Installed JMX, Thread Dumps, and Wily Introscope for comprehensive performance monitoring.
- Created automation scripts to streamline testing processes and improve efficiency.

### Senior Systems & Data Migration Engineer at Sabre
2008-05 – 2012
- Led massive data migration of a high-throughput shopping engine from 200+ MySQL nodes to a 6-node Oracle RAC cluster.
- Optimized C++ and OCCI transaction processing, reducing hardware footprint by 95% while maintaining sub-second latency.
- Built a CPPUNIT testing framework to automate conversion and ensure data integrity.
- Designed scalable solutions to handle 10x the throughput of VISA, focusing on performance optimization.
- Collaborated with teams to ensure seamless migration and system reliability.
- Developed rigorous testing strategies to validate performance and scalability post-migration.

## Education
**High Diploma / Post-Graduate Diploma in Computer Engineering Technology / Computer Science**  
Humber College, Toronto, Canada

**Bachelor of Science in Civil Engineering**  
Zagazig University, Egypt / Cairo, Egypt

## Skills
Python, SQL / Oracle, PySpark, AWS, Java, ETL Design & Optimization, Capacity Planning / Forecasting, Data Warehousing, GenAI / LLM Agents, Pandas, Prophet / Time-Series Forecasting, scikit-learn, Hive/Hadoop, Airflow, Streamlit, C++, Perl, Ksh / Korn Shell Scripting, PL/SQL, Dynatrace (AppMon + Synthetics), CA APM / Introscope, BMC TrueSight / TSCO, Oracle RAC, Multiprocessing, Docker, Git, Linux/Unix, OCCI / OCI, WebLogic / WebSphere, VB6 / VC++

## Flagship Projects
### Serverless Lakehouse Platform (AWS)
Designed a full serverless data platform using S3, Glue, Athena, and Bedrock. Built a Text-to-SQL GenAI agent with Claude 3 Sonnet. Resolved small file issues using Snappy and Parquet compression. Optimized ETL and data access for enterprise-scale performance.
**Technologies:** AWS Glue, Athena, Bedrock (GenAI), S3, PySpark

### HorizonScale — AI Capacity Forecasting Engine
Replaced legacy manual processes with a parallel generator-based pipeline, reducing forecasting cycles by 90%. Developed an interactive Streamlit dashboard for real-time capacity insights and 'High Trust' utilization scores. Built a modern agentic pipeline for banking-scale telemetry. Features include parallel forecasting and comprehensive documentation.
**Technologies:** Python, Prophet, Streamlit, PySpark, Multiprocessing, Spark, Machine Learning, Data Pipelines, API Integration, Performance Benchmarking, Testing and Validation, AI Reasoning, RAG (Retrieval-Augmented Generation)
**Repo:** [github.com/seanlgirgis/HorizonStudy](https://github.com/seanlgirgis/HorizonStudy)

### FAST Project
Conducted data mining of user performance metrics to optimize critical money-generating systems.
**Technologies:** Dynatrace, Data Mining

