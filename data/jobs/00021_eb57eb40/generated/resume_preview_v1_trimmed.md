# Tailored Resume Preview

**Sean Luka Girgis**  
Senior Data Engineer | Capacity Planning & AI-Driven Infrastructure Optimization  
214-315-2190 | seanlgirgis@gmail.com  
[LinkedIn](https://www.linkedin.com/in/sean-girgis-43bb1b5/) | [GitHub](https://github.com/seanlgirgis) | [Portfolio](https://seanlgirgis.github.io)  

## Professional Summary
Senior Data Engineer with over 20 years of enterprise experience, specializing in database engineering, cloud data architectures, and performance optimization using Snowflake, AWS, and SQL programming. Proficient in Python scripting and Linux environments, I excel in building scalable ETL pipelines and integrating data platforms with observability tools like Dynatrace and Splunk. My expertise includes CI/CD pipelines and infrastructure automation, ensuring seamless deployments and disaster recovery planning. I have a proven track record in capacity forecasting and cost optimization using FinOps principles. Passionate about driving innovation in financial markets infrastructure, I am eager to contribute to DTCC’s mission of strengthening data foundations. Experienced in Agile/Scrum methodologies, I thrive in collaborative, high-impact environments.

## Professional Experience
### Senior Capacity & Data Engineer at CITI
2017-11 – 2025-12
- Architected automated ETL pipelines using Python and Pandas to ingest P95 telemetry from 6,000+ endpoints, replacing manual processes.
- Developed ML forecasting models with Prophet and scikit-learn to predict capacity bottlenecks 6 months ahead, enhancing provisioning accuracy.
- Designed optimized Oracle schemas for historical data retention, supporting seasonal risk forecasting.
- Integrated disparate data feeds into unified Oracle reporting systems with executive dashboards.
- Identified underutilized infrastructure through data mining, driving cost savings via hardware consolidation.
- Built automated reporting workflows and interactive dashboards using Python libraries like matplotlib and plotly.

### Performance Engineer at G6 Hospitality LLC
2017-03 – 2017-11
- Managed Dynatrace AppMon/Synthetics for critical systems and Brand.com, enhancing observability.
- Led 'FAST' project to data-mine real-user performance metrics, providing optimization recommendations.
- Upgraded Dynatrace from 6.5 to 7.0, implemented TLS1.2 security, and supported AWS cloud migration.
- Provided end-to-end monitoring and dashboarding for performance metrics and bottleneck analysis.

### SME for CA APM (Senior Consultant) at CA Technologies/ TIAA-CREF
2011 – 2016
- Led large-scale CA APM implementations and upgrades (9.1 to 10.1), managing 4,000–6,000 agents.
- Designed custom Management Modules, dashboards, and alerts for performance monitoring.
- Developed Perl and Ksh scripts for data extraction and automation of monitoring tasks.
- Provided sizing recommendations, bottleneck resolution, and client training for J2EE/.NET environments.

### Performance Test Engineer at AT&T
2010-08 – 2011-07
- Analyzed J2EE telecom applications for load and breakpoints, focusing on performance optimization.
- Documented critical metrics including JDBC, threads, memory, CPU, and garbage collection.
- Installed JMX, Thread Dumps, and Wily Introscope for monitoring and diagnostics.
- Created automation scripts to streamline performance testing processes.

### Senior Systems & Data Migration Engineer at Sabre
2008-05 – 2010
- Led migration of 200+ MySQL nodes to a 6-node Oracle RAC cluster for a high-throughput shopping engine.
- Optimized C++/OCCI transaction processing, reducing hardware footprint by 95% while maintaining sub-second latency.
- Built a CPPUNIT testing framework to automate conversion and validation processes.
- Ensured high performance and scalability during data migration for critical systems.

## Education
**High Diploma / Post-Graduate Diploma in Computer Engineering Technology / Computer Science**  
Humber College, Toronto, Canada

**Bachelor of Science in Civil Engineering**  
Zagazig University, Egypt / Cairo, Egypt

## Skills
SQL / Oracle, Python, AWS, Linux/Unix, Git, Dynatrace (AppMon + Synthetics), Data Warehousing, PySpark, ETL Design & Optimization, Capacity Planning / Forecasting, Pandas, Prophet / Time-Series Forecasting, scikit-learn, GenAI / LLM Agents, Streamlit, Multiprocessing, Docker, Airflow, Hive/Hadoop, BMC TrueSight / TSCO, C++, Perl, Ksh / Korn Shell Scripting, Java, PL/SQL, CA APM / Introscope, Oracle RAC, OCCI / OCI, WebLogic / WebSphere, VB6 / VC++

## Flagship Projects
### Serverless Lakehouse Platform (AWS)
Designed a full serverless data platform using S3, Glue, Athena, and Bedrock. Built a Text-to-SQL GenAI agent with Claude 3 Sonnet. Resolved small file issues using Snappy and Parquet compression. Optimized ETL and data access for enterprise scale.
**Technologies:** AWS Glue, Athena, Bedrock (GenAI), S3, PySpark

### HorizonScale — AI Capacity Forecasting Engine
Replaced legacy manual processes with a parallel generator-based pipeline, reducing forecasting cycles by 90%. Developed an interactive Streamlit dashboard for real-time capacity insights and 'High Trust' utilization scores. Built a modern agentic pipeline for banking-scale telemetry.
**Technologies:** Python, Prophet, Streamlit, PySpark, Multiprocessing, Spark, Machine Learning, Data Pipelines, API Integration, Performance Benchmarking, Testing and Validation, AI Reasoning, RAG (Retrieval-Augmented Generation)
**Repo:** [github.com/seanlgirgis/HorizonStudy](https://github.com/seanlgirgis/HorizonStudy)

### FAST Project
Data mining user performance metrics to optimize critical money-generating systems.
**Technologies:** Dynatrace, Data Mining

