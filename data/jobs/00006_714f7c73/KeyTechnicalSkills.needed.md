Here are the key **skills and technical proficiencies** explicitly listed in the Capital One **Lead Data Engineer** job description (for the Plano, TX location). I've organized them by section for clarity, pulling directly from the posting.

### From "What Youâ€™ll Do" (Responsibilities implying required skills)
- Full-stack development tools and technologies
- Programming languages: **Java**, **Scala**, **Python**
- Open Source RDBMS and NoSQL databases
- Cloud-based data warehousing services: **Redshift**, **Snowflake**
- Machine learning (team collaboration context)
- Distributed microservices
- Unit testing, code reviews, performance tuning
- Staying current with tech trends, experimenting with new technologies
- Mentoring and participating in tech communities
- Agile collaboration and iterative delivery

### Basic Qualifications (Minimum required experience/skills)
- Bachelorâ€™s Degree
- At least 4 years of experience in application development (non-internship)
- At least 2 years of experience in **big data technologies**
- At least 1 year experience with cloud computing (**AWS**, **Microsoft Azure**, **Google Cloud**)

### Preferred Qualifications (Strongly desired / highly valued skills)
- 7+ years of experience in application development including: **Python**, **SQL**, **Scala**, or **Java**
- 4+ years of experience with a public cloud (**AWS**, **Microsoft Azure**, **Google Cloud**)
- 4+ years experience with Distributed data/computing tools: **MapReduce**, **Hadoop**, **Hive**, **EMR**, **Kafka**, **Spark**, **Gurobi**, or **MySQL**
- 4+ years experience working on **real-time data** and **streaming applications**
- 4+ years of experience with NoSQL implementation (**Mongo**, **Cassandra**)
- 4+ years of **data warehousing** experience (**Redshift** or **Snowflake**)
- 4+ years of experience with **UNIX/Linux** including basic commands and shell scripting
- 2+ years of experience with **Agile engineering practices**

These are the most concrete technical skills highlighted. The role emphasizes hands-on experience building scalable, cloud-native data solutions, especially in big data, streaming, warehousing, and modern languages/cloud platforms. Your resume already aligns well with many of these (e.g., Python, SQL, AWS, PySpark/Spark, Snowflake/Redshift, Hadoop/Hive exposure via big data work, Linux/Unix scripting, Agile practices, real-time/forecasting pipelines), so highlighting those matches in your call today will be strong.

Good luck with your 12:00 PM chat with Karahâ€”you're in a great position! Let me know how it goes or if you want help prepping talking points. ðŸš€