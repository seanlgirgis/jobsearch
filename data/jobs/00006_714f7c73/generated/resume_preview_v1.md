# Tailored Resume Preview

**Sean Luka Girgis**  
Senior Data Engineer | Capacity Planning & AI-Driven Infrastructure Optimization  
214-315-2190 | seanlgirgis@gmail.com  
[LinkedIn](https://www.linkedin.com/in/sean-girgis-43bb1b5/) | [GitHub](https://github.com/seanlgirgis) | [Portfolio](https://seanlgirgis.github.io)  

## Professional Summary
Senior Data Engineer with over 20 years of enterprise experience, specializing in big data technologies and cloud computing with expertise in Python, SQL, and AWS. Proficient in designing and implementing scalable data pipelines, leveraging tools like PySpark and Hadoop for high-scale processing. Skilled in data warehousing with platforms like Snowflake and Redshift, and experienced in Agile engineering practices for collaborative solution development. Passionate about staying ahead of tech trends and mentoring teams to deliver innovative solutions. Eager to contribute to Capital One’s mission of financial empowerment by building cloud-based, customer-focused technologies. Adept at full-stack development and distributed systems to solve real-world challenges.

## Professional Experience
### Senior Capacity & Data Engineer at CITI
2017-11 – 2025-12
- Architected automated ETL pipelines using Python and Pandas to ingest P95 telemetry from 6,000+ endpoints, replacing manual processes.
- Developed ML forecasting models with Prophet and scikit-learn to predict capacity bottlenecks 6 months ahead, enhancing provisioning accuracy.
- Designed optimized Oracle schemas for historical data retention, supporting seasonal risk forecasting.
- Built unified reporting systems integrating disparate data feeds into executive dashboards.
- Identified underutilized infrastructure through data mining, driving significant cost savings via hardware consolidation.
- Automated workflows and reporting with Python scripts, improving operational efficiency.

### Performance Engineer at G6 Hospitality LLC
2017-03 – 2017-11
- Managed Dynatrace AppMon/Synthetics for monitoring Brand.com and critical systems.
- Led 'FAST' project to data-mine real-user performance metrics, providing optimization recommendations.
- Upgraded Dynatrace from 6.5 to 7.0, implemented TLS1.2 security, and supported AWS cloud migration.
- Provided end-to-end monitoring and dashboarding for performance metrics analysis.
- Analyzed system bottlenecks and suggested actionable performance improvements.
- Integrated Performance Center with Dynatrace for comprehensive monitoring.

### Senior Consultant / SME for CA APM at CA Technologies (various clients) & Enterprise Iron (TIAA-CREF)
2011 – 2016
- Led large-scale CA APM implementations and upgrades (9.1 to 10.1) for 4,000–6,000 agents.
- Designed custom Management Modules, dashboards, alerts, and Perl/Ksh data extraction scripts.
- Provided sizing recommendations, Golden Images, and client training for APM solutions.
- Resolved performance bottlenecks in J2EE/.NET environments through detailed analysis.
- Served as CA APM SME for TIAA-CREF, managing 50+ Enterprise Managers.
- Collaborated with IT teams to troubleshoot and optimize system performance.

### Performance Test Engineer at AT&T
2010-08 – 2011-07
- Analyzed J2EE telecom applications to identify load and resource bottlenecks.
- Documented critical metrics including JDBC connections, threads, memory, CPU, and GC.
- Installed JMX monitoring, Thread Dumps, and Wily Introscope for performance tracking.
- Created automation scripts to streamline performance testing processes.

### Senior Systems & Data Migration Engineer at Sabre
2008-05 – 2012
- Led migration of 200+ MySQL nodes to a 6-node Oracle RAC cluster for a high-throughput shopping engine.
- Optimized C++/OCCI transaction processing, reducing hardware footprint by 95% while maintaining sub-second latency.
- Built a CPPUNIT testing framework to automate conversion and validation processes.
- Ensured high performance for a system handling 10x the throughput of VISA.

### Architect/Developer (IRS CADE Project) at Computer Science Corporation (CSC)
2007-10 – 2008-05
- Performed UML-based unit design for a CICS/MQSeries/XML/DB2 system.
- Developed modules for IRS modernization using VC++ and DB2.
- Contributed to messaging architecture design and implementation.

### Developer / Support Engineer (Billing, Interfaces, CSM/PRMS) at Corpus Inc. / Sprint (AMDOCS projects)
2001 – 2007
- Developed high-availability multithreaded C++ interfaces using POSIX, sockets, and Marconi APIs.
- Enhanced billing performance with C/C++/Pro*C/PL/SQL, achieving 75% memory reduction and 10x DB performance.
- Automated system administration for WebLogic/WebSphere using Korn Shell scripts.
- Designed and implemented interfaces with UML, Java, J2EE, XML, and Perl.
- Troubleshot and supported Enabler/CSM/EMS modules in production environments.
- Reverse-engineered and documented AMDOCS PRM and APIs for system enhancements.

### Developer at Simplex International - Canada
1999 – 2001
- Developed time and attendance interfaces using VB6 and VC++.

### Lab Support at Humber College
1996-09 – 1999-04
- Maintained and troubleshot Linux and Windows systems as part of the Lab Support team.
- Performed various administrative tasks to ensure lab functionality.

## Education
**High Diploma / Post-Graduate Diploma in Computer Engineering Technology / Computer Science**  
Humber College, Toronto, Canada

**Bachelor of Science in Civil Engineering**  
Zagazig University, Egypt / Cairo, Egypt

## Skills
Python, SQL / Oracle, AWS, PySpark, Java, Hive/Hadoop, Data Warehousing, Linux/Unix, Capacity Planning / Forecasting, ETL Design & Optimization, Pandas, Prophet / Time-Series Forecasting, scikit-learn, GenAI / LLM Agents, Streamlit, Multiprocessing, Docker, Git, Airflow, C++, Perl, Ksh / Korn Shell Scripting, PL/SQL, Dynatrace (AppMon + Synthetics), CA APM / Introscope, BMC TrueSight / TSCO, Oracle RAC, OCCI / OCI, WebLogic / WebSphere, VB6 / VC++

## Flagship Projects
### Serverless Lakehouse Platform (AWS)
Designed a full serverless data platform using S3, Glue, Athena, and Bedrock. Built a Text-to-SQL GenAI agent with Claude 3 Sonnet. Resolved small file issues using Snappy and Parquet compression. Optimized ETL and data access for enterprise scale.
**Technologies:** AWS Glue, Athena, Bedrock (GenAI), S3, PySpark

### HorizonScale — AI Capacity Forecasting Engine
Replaced legacy manual processes with a parallel generator-based pipeline, reducing forecasting cycles by 90%. Developed an interactive Streamlit dashboard for real-time capacity insights and 'High Trust' utilization scores. Built a modern agentic pipeline for banking-scale telemetry. Features include parallel forecasting and comprehensive documentation.
**Technologies:** Python, Prophet, Streamlit, PySpark, Multiprocessing, Spark, Machine Learning, Data Pipelines, API Integration, Performance Benchmarking, Testing and Validation, AI Reasoning, RAG (Retrieval-Augmented Generation)
**Repo:** [github.com/seanlgirgis/HorizonStudy](https://github.com/seanlgirgis/HorizonStudy)

### FAST Project
Conducted data mining of user performance metrics to optimize critical money-generating systems.
**Technologies:** Dynatrace, Data Mining

