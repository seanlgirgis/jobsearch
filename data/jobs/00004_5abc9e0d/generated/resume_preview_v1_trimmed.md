# Tailored Resume Preview

**Sean Luka Girgis**  
Senior Data Engineer | Capacity Planning & AI-Driven Infrastructure Optimization  
214-315-2190 | seanlgirgis@gmail.com  
[LinkedIn](https://www.linkedin.com/in/sean-girgis-43bb1b5/) | [GitHub](https://github.com/seanlgirgis) | [Portfolio](https://seanlgirgis.github.io)  

## Professional Summary
Senior Data Engineer with over 20 years of enterprise experience, specializing in designing scalable data infrastructure and high-performance platforms using Apache Spark, Python, and AWS. Expert in building serverless architectures, optimizing distributed systems, and implementing Data Lakehouse components for core data use cases. Proficient in cloud computing with hands-on expertise in AWS, alongside strong skills in PySpark for large-scale telemetry processing. Adept at performance optimization, capacity forecasting, and continuous delivery practices. Passionate about driving innovation through open-source frameworks and contributing to technology communities. Eager to support GEICO’s transformation into a tech-focused organization by leveraging engineering excellence in data infrastructure.

## Professional Experience
### Senior Capacity & Data Engineer at CITI
2017-11 – 2025-12
- Architected automated ETL pipelines using Python and Pandas to ingest P95 telemetry from 6,000+ endpoints, replacing manual processes.
- Developed ML forecasting models with Prophet and scikit-learn to predict capacity bottlenecks 6 months ahead, enhancing provisioning accuracy.
- Designed optimized Oracle schemas for historical data retention, supporting seasonal risk forecasting.
- Integrated disparate data feeds into unified reporting systems with executive dashboards for actionable insights.
- Identified underutilized infrastructure through data mining, driving significant cost savings via hardware consolidation.
- Built automated workflows and interactive dashboards using Python libraries like matplotlib and plotly for capacity analysis.

### Performance Engineer at G6 Hospitality LLC
2017-03 – 2017-11
- Managed Dynatrace AppMon and Synthetics for monitoring Brand.com and critical systems performance.
- Led 'FAST' project to data-mine real-user performance metrics, providing optimization recommendations.
- Upgraded Dynatrace from 6.5 to 7.0, implemented TLS1.2 security, and supported AWS cloud migration.
- Developed dashboards for end-to-end functionality and performance metrics analysis.
- Analyzed system bottlenecks and proposed actionable performance improvements.
- Integrated Performance Center with Dynatrace for comprehensive monitoring solutions.

### Senior Consultant / SME for CA APM at CA Technologies (various clients) & Enterprise Iron (TIAA-CREF)
2011 – 2016
- Led large-scale CA APM implementations and upgrades (9.1 to 10.1), managing 4,000–6,000 agents across environments.
- Designed custom Management Modules, dashboards, alerts, and Perl/Ksh scripts for data extraction.
- Provided sizing recommendations, created Golden Images, and trained clients on APM solutions.
- Resolved performance bottlenecks in J2EE and .NET environments through detailed analysis.
- Served as CA APM SME for TIAA-CREF, overseeing 50+ Enterprise Managers and extensive agent deployments.
- Collaborated with IT teams to troubleshoot and optimize performance in complex WebLogic environments.

### Performance Test Engineer at AT&T
2010-08 – 2011-07
- Analyzed J2EE telecom applications to identify load and break points for optimal performance.
- Documented critical metrics including JDBC connections, threads, memory, CPU, and garbage collection.
- Installed JMX, Thread Dumps, and Wily Introscope for comprehensive monitoring.
- Created automation scripts to streamline performance testing processes.

### Senior Systems & Data Migration Engineer at Sabre
2008-05 – 2012
- Led migration of 200+ MySQL nodes to a 6-node Oracle RAC cluster for a high-throughput shopping engine.
- Optimized C++ and OCCI transaction processing, reducing hardware footprint by 95% while maintaining sub-second latency.
- Developed a CPPUNIT testing framework to automate conversion and validation processes.
- Ensured high performance and scalability for a system handling transaction volumes exceeding VISA’s throughput.
- Collaborated with teams to refactor and enhance distributed system architecture.
- Documented migration strategies and performance benchmarks for future reference.

## Education
**High Diploma / Post-Graduate Diploma in Computer Engineering Technology / Computer Science**  
Humber College, Toronto, Canada

**Bachelor of Science in Civil Engineering**  
Zagazig University, Egypt / Cairo, Egypt

## Skills
Python, AWS, PySpark, Java, Docker, Capacity Planning / Forecasting, Distributed Systems, Cloud Computing, SQL / Oracle, C++, Perl, Ksh / Korn Shell Scripting, PL/SQL, Prophet / Time-Series Forecasting, GenAI / LLM Agents, Pandas, scikit-learn, Dynatrace (AppMon + Synthetics), CA APM / Introscope, BMC TrueSight / TSCO, Oracle RAC, ETL Design & Optimization, Data Warehousing, Streamlit, Multiprocessing, Git, Airflow, Hive/Hadoop, Linux/Unix, OCCI / OCI, WebLogic / WebSphere, VB6 / VC++

## Flagship Projects
### Serverless Lakehouse Platform (AWS)
Designed a full serverless data platform using S3, Glue, Athena, and Bedrock. Built a Text-to-SQL GenAI agent with Claude 3 Sonnet. Resolved small file issues using Snappy and Parquet compression. Optimized ETL and data access for enterprise-scale performance.
**Technologies:** AWS Glue, Athena, Bedrock (GenAI), S3, PySpark

### HorizonScale — AI Capacity Forecasting Engine
Replaced legacy manual processes with a parallel generator-based pipeline, reducing forecasting cycles by 90%. Developed an interactive Streamlit dashboard for real-time capacity insights and 'High Trust' utilization scores. Engineered a modern agentic pipeline for banking-scale telemetry. Featured advanced ML models and comprehensive documentation.
**Technologies:** Python, Prophet, Streamlit, PySpark, Multiprocessing, Spark, Machine Learning, Data Pipelines, API Integration, Performance Benchmarking, Testing and Validation, AI Reasoning, RAG (Retrieval-Augmented Generation)
**Repo:** [github.com/seanlgirgis/HorizonStudy](https://github.com/seanlgirgis/HorizonStudy)

### FAST Project
Conducted data mining of user performance metrics to optimize critical money-generating systems.
**Technologies:** Dynatrace, Data Mining

