# Tailored Resume Preview

**Sean Luka Girgis**  
Senior Data Engineer | Capacity Planning & AI-Driven Infrastructure Optimization  
214-315-2190 | seanlgirgis@gmail.com  
[LinkedIn](https://www.linkedin.com/in/sean-girgis-43bb1b5/) | [GitHub](https://github.com/seanlgirgis) | [Portfolio](https://seanlgirgis.github.io)  

## Professional Summary
Senior Data Engineer with over 20 years of enterprise experience, specializing in designing scalable data pipelines and cloud-based data solutions using Python, PySpark, and AWS. Proficient in building end-to-end ETL processes for Big Data environments, leveraging tools like Spark, S3, and cloud data warehouses such as Snowflake and Redshift. Adept at ensuring data security and delivering high-quality data products through Agile practices. Experienced in lakehouse architectures and modern data stacks, with a focus on optimizing data infrastructure. Passionate about contributing to Stefanini Group’s mission of enhancing user experience through the Common Data Platform. Eager to collaborate with cross-functional teams to drive innovative data engineering solutions.

## Professional Experience
### Senior Capacity & Data Engineer at CITI
2017-11 – 2025-12
- Architected automated ETL pipelines using Python and Pandas to ingest P95 telemetry from 6,000+ endpoints, replacing manual processes.
- Developed ML forecasting models with Prophet and scikit-learn to predict bottlenecks 6 months ahead, enhancing provisioning accuracy.
- Built unified Oracle reporting systems with executive dashboards by integrating disparate data feeds.
- Designed optimized Oracle schemas for historical data retention, supporting seasonal risk forecasting.
- Automated data pipelines for capacity metrics, ensuring data reliability and availability.
- Identified underutilized infrastructure through data mining, driving significant cost savings via hardware consolidation.

### Performance Engineer at G6 Hospitality LLC
2017-03 – 2017-11
- Managed Dynatrace AppMon/Synthetics for monitoring Brand.com and critical systems.
- Led 'FAST' project to data-mine real-user performance metrics, providing optimization recommendations.
- Supported cloud migration to AWS, ensuring seamless performance monitoring.
- Upgraded Dynatrace from 6.5 to 7.0, enhancing security with TLS1.2.
- Analyzed bottlenecks and suggested performance improvements for critical systems.
- Provided end-to-end monitoring and dashboarding for before/after performance metrics.

### Senior Consultant / SME for CA APM at CA Technologies (various clients) & Enterprise Iron (TIAA-CREF)
2011 – 2016
- Led large-scale CA APM implementations and upgrades (9.1 to 10.1), managing 4,000–6,000 agents.
- Designed custom Management Modules, dashboards, alerts, and Perl/Ksh data extraction scripts.
- Provided sizing recommendations, Golden Images, and client training for APM solutions.
- Resolved performance bottlenecks in J2EE/.NET environments through detailed analysis.
- Served as CA APM SME for TIAA-CREF, overseeing 50+ Enterprise Managers.
- Collaborated with IT teams to troubleshoot and optimize performance in WebLogic environments.

### Performance Test Engineer at AT&T
2010-08 – 2011-07
- Analyzed J2EE telecom applications to identify load and resource bottlenecks.
- Documented key performance metrics including JDBC connections, threads, memory, CPU, and GC.
- Installed JMX monitoring and Wily Introscope for performance tracking.
- Created automation scripts to streamline performance testing processes.

### Senior Systems & Data Migration Engineer at Sabre
2008-05 – 2012
- Led migration of 200+ MySQL nodes to a 6-node Oracle RAC cluster for a high-throughput shopping engine.
- Optimized C++/OCCI transaction processing, reducing hardware footprint by 95% while maintaining sub-second latency.
- Built a CPPUNIT testing framework to automate conversion processes.
- Ensured high availability and performance for a system handling 10x VISA’s throughput.
- Collaborated with teams to refactor and optimize database architecture.
- Developed automated testing solutions to validate migration integrity.

### Architect/Developer (IRS CADE Project) at Computer Science Corporation (CSC)
2007-10 – 2008-05
- Performed UML-based unit design for a CICS/MQSeries/XML/DB2 system.
- Developed modules for IRS modernization using VC++ and DB2.
- Contributed to messaging architecture design with XML integration.

### Developer / Support Engineer (Billing, Interfaces, CSM/PRMS) at Corpus Inc. / Sprint (AMDOCS projects)
2001 – 2007
- Developed high-availability multithreaded C++ interfaces using POSIX, sockets, and Marconi APIs.
- Enhanced billing performance with C/C++/Pro*C/PL/SQL, achieving 75% memory reduction and 10x DB performance.
- Automated system administration for WebLogic/WebSphere using Korn Shell scripts.
- Designed and implemented interfaces with UML, Java, J2EE, and XML.
- Troubleshot and supported Enabler/CSM/EMS modules in production environments.
- Reverse-engineered and documented AMDOCS PRM and APIs for system enhancements.

### Developer at Simplex International - Canada
1999 – 2001
- Developed time and attendance interfaces using VB6 and VC++.

### Lab Support at Humber College
1996-09 – 1999-04
- Maintained and troubleshot Linux and Windows systems as part of the Lab Support team.
- Performed various administrative tasks to ensure lab functionality.

## Education
**High Diploma / Post-Graduate Diploma in Computer Engineering Technology / Computer Science**  
Humber College, Toronto, Canada

**Bachelor of Science in Civil Engineering**  
Zagazig University, Egypt / Cairo, Egypt

## Skills
Python, PySpark, SQL / Oracle, AWS, ETL Design & Optimization, Spark, Airflow, Data Warehousing, Pandas, Hive/Hadoop, Capacity Planning / Forecasting, Prophet / Time-Series Forecasting, scikit-learn, GenAI / LLM Agents, Streamlit, Git, Docker, Linux/Unix, Multiprocessing, BMC TrueSight / TSCO, C++, PL/SQL, Oracle RAC, OCCI / OCI, Java, Perl, Ksh / Korn Shell Scripting, Dynatrace (AppMon + Synthetics), CA APM / Introscope, WebLogic / WebSphere, VB6 / VC++

## Flagship Projects
### Serverless Lakehouse Platform (AWS)
Designed a full serverless data platform using S3, Glue, Athena, and Bedrock. Built a Text-to-SQL GenAI agent with Claude 3 Sonnet. Resolved small file issues using Snappy and Parquet compression. Optimized ETL and data access for enterprise-scale lakehouse architectures.
**Technologies:** AWS Glue, Athena, Bedrock (GenAI), S3, PySpark

### HorizonScale — AI Capacity Forecasting Engine
Replaced legacy manual processes with a parallel generator-based pipeline, reducing forecasting cycles by 90%. Developed an interactive Streamlit dashboard for real-time capacity insights and 'High Trust' utilization scores. Built a modern agentic pipeline for banking-scale telemetry. Featured extensive documentation and performance benchmarks.
**Technologies:** Python, Prophet, Streamlit, PySpark, Multiprocessing, Spark, Machine Learning, Data Pipelines, API Integration, Performance Benchmarking, Testing and Validation, AI Reasoning, RAG (Retrieval-Augmented Generation)
**Repo:** [github.com/seanlgirgis/HorizonStudy](https://github.com/seanlgirgis/HorizonStudy)

### FAST Project
Conducted data mining on user performance metrics to optimize critical money-generating systems.
**Technologies:** Dynatrace, Data Mining

