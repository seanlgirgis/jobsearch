{
  "personal": {
    "full_name": "Sean Luka Girgis",
    "previous_name": "Emad Girgis",
    "name_change_note": "Changed approximately 9 years ago (around 2017)",
    "preferred_title": "Senior Data Engineer | Capacity Planning & AI-Driven Infrastructure Optimization",
    "address": "Murphy, TX (Plano area) / 424 Oriole Dr., Murphy, TX 75094",
    "phone": "214-315-2190",
    "email": "seanlgirgis@gmail.com",
    "linkedin": "https://www.linkedin.com/in/sean-girgis-43bb1b5/",
    "github": "https://github.com/seanlgirgis",
    "personal_website": "https://seanlgirgis.github.io",
    "x_twitter": "https://x.com/SeanLuka22249",
    "location_preference": "Plano, TX / Dallas-Fort Worth / Remote",
    "target_roles": [
      "Senior Data Engineer",
      "AI Engineer",
      "Cloud Data Architect",
      "Capacity Planning Engineer",
      "PySpark / AWS Specialist"
    ]
  },
  "summary": "Senior Data Engineer with over 20 years of enterprise experience, specializing in designing scalable data pipelines and cloud-based data solutions using Python, PySpark, and AWS. Proficient in building end-to-end ETL processes for Big Data environments, leveraging tools like Spark, S3, and cloud data warehouses such as Snowflake and Redshift. Adept at ensuring data security and delivering high-quality data products through Agile practices. Experienced in lakehouse architectures and modern data stacks, with a focus on optimizing data infrastructure. Passionate about contributing to Stefanini Group’s mission of enhancing user experience through the Common Data Platform. Eager to collaborate with cross-functional teams to drive innovative data engineering solutions.",
  "skills": [
    {
      "name": "Python",
      "years": 15,
      "proficiency": "Expert",
      "last_used": "2025",
      "categories": [
        "Data Engineering"
      ],
      "notes": "Pandas, generators, ETL pipelines, scripting, multiprocessing"
    },
    {
      "name": "PySpark",
      "years": 6,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Big Data"
      ],
      "notes": "Large-scale telemetry processing, parallel forecasting, spark, data-engineering"
    },
    {
      "name": "SQL / Oracle",
      "years": 18,
      "proficiency": "Expert",
      "last_used": "2025",
      "categories": [
        "Databases"
      ],
      "notes": "Schema design, partitioning, PL/SQL, Pro*C, querying"
    },
    {
      "name": "AWS",
      "years": 7,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Cloud"
      ],
      "notes": "Glue, Athena, S3, Bedrock, serverless architectures, infrastructure"
    },
    {
      "name": "ETL Design & Optimization",
      "years": 15,
      "proficiency": "Expert",
      "last_used": "2025",
      "categories": [
        "Data Engineering"
      ],
      "notes": "Data pipelines, reporting"
    },
    {
      "name": "Spark",
      "years": 6,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Big Data"
      ],
      "notes": "Large-scale telemetry processing, parallel forecasting"
    },
    {
      "name": "Airflow",
      "years": 5,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Orchestration"
      ],
      "notes": "Data-engineering"
    },
    {
      "name": "Data Warehousing",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Data Engineering"
      ],
      "notes": "Snowflake/Redshift, Parquet/Snappy"
    },
    {
      "name": "Pandas",
      "years": 10,
      "proficiency": "Expert",
      "last_used": "2025",
      "categories": [
        "Data Engineering"
      ],
      "notes": "Data pipelines, ETL processes"
    },
    {
      "name": "Hive/Hadoop",
      "years": 7,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Big Data"
      ],
      "notes": ""
    },
    {
      "name": "Capacity Planning / Forecasting",
      "years": 15,
      "proficiency": "Expert",
      "last_used": "2025",
      "categories": [
        "Infrastructure"
      ],
      "notes": "ML, infrastructure"
    },
    {
      "name": "Prophet / Time-Series Forecasting",
      "years": 5,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Machine Learning"
      ],
      "notes": "Capacity bottleneck prediction, with scikit-learn, forecasting, statistics"
    },
    {
      "name": "scikit-learn",
      "years": 6,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Machine Learning"
      ],
      "notes": "ML forecasting, statistical analysis"
    },
    {
      "name": "GenAI / LLM Agents",
      "years": 2,
      "proficiency": "Intermediate-Advanced",
      "last_used": "2025",
      "categories": [
        "AI"
      ],
      "notes": "Text-to-SQL agents, Claude 3 Sonnet integration, llm, agents"
    },
    {
      "name": "Streamlit",
      "years": 3,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Visualization"
      ],
      "notes": "Dashboards, python"
    },
    {
      "name": "Git",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Version Control"
      ],
      "notes": ""
    },
    {
      "name": "Docker",
      "years": 5,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "DevOps"
      ],
      "notes": "Containerization"
    },
    {
      "name": "Linux/Unix",
      "years": 20,
      "proficiency": "Expert",
      "last_used": "2025",
      "categories": [
        "OS"
      ],
      "notes": "HPUX, SunOS, Red Hat, infrastructure"
    },
    {
      "name": "Multiprocessing",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Programming"
      ],
      "notes": "Performance"
    },
    {
      "name": "BMC TrueSight / TSCO",
      "years": 7,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Monitoring"
      ],
      "notes": "Capacity optimization, Aperature Vista"
    },
    {
      "name": "C++",
      "years": 20,
      "proficiency": "Expert",
      "last_used": "2010",
      "categories": [
        "Programming"
      ],
      "notes": "POSIX Threads, STL, OCCI/OCI, Multithreading, high-performance"
    },
    {
      "name": "PL/SQL",
      "years": 18,
      "proficiency": "Expert",
      "last_used": "2010",
      "categories": [
        "Databases"
      ],
      "notes": "DB performance, pair with Oracle"
    },
    {
      "name": "Oracle RAC",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2010",
      "categories": [
        "Databases"
      ],
      "notes": "High-availability, oracle"
    },
    {
      "name": "OCCI / OCI",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2010",
      "categories": [
        "Databases"
      ],
      "notes": "Oracle"
    },
    {
      "name": "Java",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2016",
      "categories": [
        "Programming"
      ],
      "notes": "J2EE (EJB, JMS, Servlets), backend, performance testing/APM"
    },
    {
      "name": "Perl",
      "years": 12,
      "proficiency": "Advanced",
      "last_used": "2016",
      "categories": [
        "Scripting"
      ],
      "notes": "Automation, data extraction"
    },
    {
      "name": "Ksh / Korn Shell Scripting",
      "years": 12,
      "proficiency": "Advanced",
      "last_used": "2016",
      "categories": [
        "Scripting"
      ],
      "notes": "System admin/automation, shell, linux"
    },
    {
      "name": "Dynatrace (AppMon + Synthetics)",
      "years": 8,
      "proficiency": "Expert",
      "last_used": "2017",
      "categories": [
        "Monitoring"
      ],
      "notes": "APM, observability, Gomez Synthetic Monitoring"
    },
    {
      "name": "CA APM / Introscope",
      "years": 10,
      "proficiency": "Expert",
      "last_used": "2017",
      "categories": [
        "Monitoring"
      ],
      "notes": "APM, CA CEM, CA ADA, Team Center, Command Center"
    },
    {
      "name": "WebLogic / WebSphere",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2011",
      "categories": [
        "Application Servers"
      ],
      "notes": ""
    },
    {
      "name": "VB6 / VC++",
      "years": 5,
      "proficiency": "Intermediate",
      "last_used": "2001",
      "categories": [
        "Programming"
      ],
      "notes": "Legacy"
    }
  ],
  "flagship_projects": [
    {
      "name": "Serverless Lakehouse Platform (AWS)",
      "description": "Designed a full serverless data platform using S3, Glue, Athena, and Bedrock. Built a Text-to-SQL GenAI agent with Claude 3 Sonnet. Resolved small file issues using Snappy and Parquet compression. Optimized ETL and data access for enterprise-scale lakehouse architectures.",
      "technologies": [
        "AWS Glue",
        "Athena",
        "Bedrock (GenAI)",
        "S3",
        "PySpark"
      ],
      "timeframe": "Recent"
    },
    {
      "name": "HorizonScale — AI Capacity Forecasting Engine",
      "description": "Replaced legacy manual processes with a parallel generator-based pipeline, reducing forecasting cycles by 90%. Developed an interactive Streamlit dashboard for real-time capacity insights and 'High Trust' utilization scores. Built a modern agentic pipeline for banking-scale telemetry. Featured extensive documentation and performance benchmarks.",
      "technologies": [
        "Python",
        "Prophet",
        "Streamlit",
        "PySpark",
        "Multiprocessing",
        "Spark",
        "Machine Learning",
        "Data Pipelines",
        "API Integration",
        "Performance Benchmarking",
        "Testing and Validation",
        "AI Reasoning",
        "RAG (Retrieval-Augmented Generation)"
      ],
      "repo": "https://github.com/seanlgirgis/HorizonStudy",
      "documentation": [
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/README.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/API_AND_INTEGRATION_GUIDE.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/FUTURE_ROADMAP.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/OPERATIONAL_RUNBOOK.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/PERFORMANCE_BENCHMARK_REPORT.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/TESTING_AND_VALIDATION_STRATEGY.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/TREND_TO_HORIZONSCALE_EVOLUTION.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/lessons_learnt.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/AI_REASONING_AND_RAG_SPEC.md"
      ],
      "code": "https://github.com/seanlgirgis/HorizonStudy/tree/main/src/HorizonScale",
      "additional_docs": [
        "https://github.com/seanlgirgis/HorizonStudy/tree/main/Docs/lib",
        "https://github.com/seanlgirgis/HorizonStudy/tree/main/Docs/pipeline",
        "https://github.com/seanlgirgis/HorizonStudy/tree/main/Docs/synthetic"
      ],
      "timeframe": "Recent"
    },
    {
      "name": "FAST Project",
      "description": "Conducted data mining on user performance metrics to optimize critical money-generating systems.",
      "technologies": [
        "Dynatrace",
        "Data Mining"
      ],
      "timeframe": "2017"
    }
  ],
  "experience": [
    {
      "company": "CITI",
      "title": "Senior Capacity & Data Engineer",
      "start_date": "2017-11",
      "end_date": "2025-12",
      "bullets": [
        "Architected automated ETL pipelines using Python and Pandas to ingest P95 telemetry from 6,000+ endpoints, replacing manual processes.",
        "Developed ML forecasting models with Prophet and scikit-learn to predict bottlenecks 6 months ahead, enhancing provisioning accuracy.",
        "Built unified Oracle reporting systems with executive dashboards by integrating disparate data feeds.",
        "Designed optimized Oracle schemas for historical data retention, supporting seasonal risk forecasting.",
        "Automated data pipelines for capacity metrics, ensuring data reliability and availability.",
        "Identified underutilized infrastructure through data mining, driving significant cost savings via hardware consolidation."
      ]
    },
    {
      "company": "G6 Hospitality LLC",
      "title": "Performance Engineer",
      "start_date": "2017-03",
      "end_date": "2017-11",
      "bullets": [
        "Managed Dynatrace AppMon/Synthetics for monitoring Brand.com and critical systems.",
        "Led 'FAST' project to data-mine real-user performance metrics, providing optimization recommendations.",
        "Supported cloud migration to AWS, ensuring seamless performance monitoring.",
        "Upgraded Dynatrace from 6.5 to 7.0, enhancing security with TLS1.2.",
        "Analyzed bottlenecks and suggested performance improvements for critical systems.",
        "Provided end-to-end monitoring and dashboarding for before/after performance metrics."
      ]
    },
    {
      "company": "HCL / Entergy",
      "title": "APM Consultant",
      "start_date": "2017-01",
      "end_date": "2017-03",
      "bullets": [
        "Supported enterprise CA APM, CEM, and ADA for utility systems.",
        "Managed and supported monitoring solutions including CA APM, CA CEM, and CA ADA."
      ],
      "exclude_from_resume": true
    },
    {
      "company": "CA Technologies (various clients) & Enterprise Iron (TIAA-CREF)",
      "title": "Senior Consultant / SME for CA APM",
      "start_date": "2011",
      "end_date": "2016",
      "bullets": [
        "Led large-scale CA APM implementations and upgrades (9.1 to 10.1), managing 4,000–6,000 agents.",
        "Designed custom Management Modules, dashboards, alerts, and Perl/Ksh data extraction scripts.",
        "Provided sizing recommendations, Golden Images, and client training for APM solutions.",
        "Resolved performance bottlenecks in J2EE/.NET environments through detailed analysis.",
        "Served as CA APM SME for TIAA-CREF, overseeing 50+ Enterprise Managers.",
        "Collaborated with IT teams to troubleshoot and optimize performance in WebLogic environments."
      ]
    },
    {
      "company": "AT&T",
      "title": "Performance Test Engineer",
      "start_date": "2010-08",
      "end_date": "2011-07",
      "bullets": [
        "Analyzed J2EE telecom applications to identify load and resource bottlenecks.",
        "Documented key performance metrics including JDBC connections, threads, memory, CPU, and GC.",
        "Installed JMX monitoring and Wily Introscope for performance tracking.",
        "Created automation scripts to streamline performance testing processes."
      ]
    },
    {
      "company": "Sabre",
      "title": "Senior Systems & Data Migration Engineer",
      "start_date": "2008-05",
      "end_date": "2012",
      "bullets": [
        "Led migration of 200+ MySQL nodes to a 6-node Oracle RAC cluster for a high-throughput shopping engine.",
        "Optimized C++/OCCI transaction processing, reducing hardware footprint by 95% while maintaining sub-second latency.",
        "Built a CPPUNIT testing framework to automate conversion processes.",
        "Ensured high availability and performance for a system handling 10x VISA’s throughput.",
        "Collaborated with teams to refactor and optimize database architecture.",
        "Developed automated testing solutions to validate migration integrity."
      ]
    },
    {
      "company": "Computer Science Corporation (CSC)",
      "title": "Architect/Developer (IRS CADE Project)",
      "start_date": "2007-10",
      "end_date": "2008-05",
      "bullets": [
        "Performed UML-based unit design for a CICS/MQSeries/XML/DB2 system.",
        "Developed modules for IRS modernization using VC++ and DB2.",
        "Contributed to messaging architecture design with XML integration."
      ]
    },
    {
      "company": "Corpus Inc. / Sprint (AMDOCS projects)",
      "title": "Developer / Support Engineer (Billing, Interfaces, CSM/PRMS)",
      "start_date": "2001",
      "end_date": "2007",
      "bullets": [
        "Developed high-availability multithreaded C++ interfaces using POSIX, sockets, and Marconi APIs.",
        "Enhanced billing performance with C/C++/Pro*C/PL/SQL, achieving 75% memory reduction and 10x DB performance.",
        "Automated system administration for WebLogic/WebSphere using Korn Shell scripts.",
        "Designed and implemented interfaces with UML, Java, J2EE, and XML.",
        "Troubleshot and supported Enabler/CSM/EMS modules in production environments.",
        "Reverse-engineered and documented AMDOCS PRM and APIs for system enhancements."
      ]
    },
    {
      "company": "Simplex International - Canada",
      "title": "Developer",
      "start_date": "1999",
      "end_date": "2001",
      "bullets": [
        "Developed time and attendance interfaces using VB6 and VC++."
      ]
    },
    {
      "company": "Humber College",
      "title": "Lab Support",
      "start_date": "1996-09",
      "end_date": "1999-04",
      "bullets": [
        "Maintained and troubleshot Linux and Windows systems as part of the Lab Support team.",
        "Performed various administrative tasks to ensure lab functionality."
      ]
    }
  ],
  "education": [
    {
      "degree": "High Diploma / Post-Graduate Diploma in Computer Engineering Technology / Computer Science",
      "institution": "Humber College",
      "location": "Toronto, Canada",
      "dates": "Not specified"
    },
    {
      "degree": "Bachelor of Science in Civil Engineering",
      "institution": "Zagazig University",
      "location": "Egypt / Cairo, Egypt",
      "dates": "Not specified"
    }
  ]
}