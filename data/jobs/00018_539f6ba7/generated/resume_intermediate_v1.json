{
  "personal": {
    "full_name": "Sean Luka Girgis",
    "previous_name": "Emad Girgis",
    "name_change_note": "Changed approximately 9 years ago (around 2017)",
    "preferred_title": "Senior Data Engineer | Capacity Planning & AI-Driven Infrastructure Optimization",
    "address": "Murphy, TX (Plano area) / 424 Oriole Dr., Murphy, TX 75094",
    "phone": "214-315-2190",
    "email": "seanlgirgis@gmail.com",
    "linkedin": "https://www.linkedin.com/in/sean-girgis-43bb1b5/",
    "github": "https://github.com/seanlgirgis",
    "personal_website": "https://seanlgirgis.github.io",
    "x_twitter": "https://x.com/SeanLuka22249",
    "location_preference": "Plano, TX / Dallas-Fort Worth / Remote",
    "target_roles": [
      "Senior Data Engineer",
      "AI Engineer",
      "Cloud Data Architect",
      "Capacity Planning Engineer",
      "PySpark / AWS Specialist"
    ]
  },
  "summary": "Senior Data Engineer with over 20 years of enterprise experience, specializing in data analysis, system architecture, and technical problem-solving with proficiency in SQL, Python, Java, and C++. Adept at building scalable data infrastructure and optimizing workflows through data engineering and business intelligence practices. Experienced in leveraging relational databases and data science techniques to drive actionable insights and process improvements. Passionate about translating business goals into technical solutions, with a strong focus on operational reviews and product activation systems. Eager to contribute to YouTube’s mission of empowering creators and partners within Google’s innovative ecosystem by driving strategic initiatives for the partner ecosystem.",
  "skills": [
    {
      "name": "SQL / Oracle",
      "years": 18,
      "proficiency": "Expert",
      "last_used": "2025",
      "categories": [
        "Databases"
      ],
      "notes": "Schema design, partitioning, PL/SQL, Pro*C, querying"
    },
    {
      "name": "Python",
      "years": 15,
      "proficiency": "Expert",
      "last_used": "2025",
      "categories": [
        "Data Engineering"
      ],
      "notes": "Pandas, generators, ETL pipelines, scripting, multiprocessing"
    },
    {
      "name": "Java",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2016",
      "categories": [
        "Programming"
      ],
      "notes": "J2EE (EJB, JMS, Servlets), backend, performance testing/APM"
    },
    {
      "name": "C++",
      "years": 20,
      "proficiency": "Expert",
      "last_used": "2010",
      "categories": [
        "Programming"
      ],
      "notes": "POSIX Threads, STL, OCCI/OCI, Multithreading, high-performance"
    },
    {
      "name": "ETL Design & Optimization",
      "years": 15,
      "proficiency": "Expert",
      "last_used": "2025",
      "categories": [
        "Data Engineering"
      ],
      "notes": "Data pipelines, reporting"
    },
    {
      "name": "Data Warehousing",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Data Engineering"
      ],
      "notes": "Snowflake/Redshift, Parquet/Snappy"
    },
    {
      "name": "Pandas",
      "years": 10,
      "proficiency": "Expert",
      "last_used": "2025",
      "categories": [
        "Data Engineering"
      ],
      "notes": "Data pipelines, ETL processes"
    },
    {
      "name": "scikit-learn",
      "years": 6,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Machine Learning"
      ],
      "notes": "ML forecasting, statistical analysis"
    },
    {
      "name": "AWS",
      "years": 7,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Cloud"
      ],
      "notes": "Glue, Athena, S3, Bedrock, serverless architectures, infrastructure"
    },
    {
      "name": "PySpark",
      "years": 6,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Big Data"
      ],
      "notes": "Large-scale telemetry processing, parallel forecasting, spark, data-engineering"
    },
    {
      "name": "Prophet / Time-Series Forecasting",
      "years": 5,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Machine Learning"
      ],
      "notes": "Capacity bottleneck prediction, with scikit-learn, forecasting, statistics"
    },
    {
      "name": "Capacity Planning / Forecasting",
      "years": 15,
      "proficiency": "Expert",
      "last_used": "2025",
      "categories": [
        "Infrastructure"
      ],
      "notes": "ML, infrastructure"
    },
    {
      "name": "GenAI / LLM Agents",
      "years": 2,
      "proficiency": "Intermediate-Advanced",
      "last_used": "2025",
      "categories": [
        "AI"
      ],
      "notes": "Text-to-SQL agents, Claude 3 Sonnet integration, llm, agents"
    },
    {
      "name": "Streamlit",
      "years": 3,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Visualization"
      ],
      "notes": "Dashboards, python"
    },
    {
      "name": "PL/SQL",
      "years": 18,
      "proficiency": "Expert",
      "last_used": "2010",
      "categories": [
        "Databases"
      ],
      "notes": "DB performance, pair with Oracle"
    },
    {
      "name": "Perl",
      "years": 12,
      "proficiency": "Advanced",
      "last_used": "2016",
      "categories": [
        "Scripting"
      ],
      "notes": "Automation, data extraction"
    },
    {
      "name": "Ksh / Korn Shell Scripting",
      "years": 12,
      "proficiency": "Advanced",
      "last_used": "2016",
      "categories": [
        "Scripting"
      ],
      "notes": "System admin/automation, shell, linux"
    },
    {
      "name": "Dynatrace (AppMon + Synthetics)",
      "years": 8,
      "proficiency": "Expert",
      "last_used": "2017",
      "categories": [
        "Monitoring"
      ],
      "notes": "APM, observability, Gomez Synthetic Monitoring"
    },
    {
      "name": "CA APM / Introscope",
      "years": 10,
      "proficiency": "Expert",
      "last_used": "2017",
      "categories": [
        "Monitoring"
      ],
      "notes": "APM, CA CEM, CA ADA, Team Center, Command Center"
    },
    {
      "name": "BMC TrueSight / TSCO",
      "years": 7,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Monitoring"
      ],
      "notes": "Capacity optimization, Aperature Vista"
    },
    {
      "name": "Oracle RAC",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2010",
      "categories": [
        "Databases"
      ],
      "notes": "High-availability, oracle"
    },
    {
      "name": "Multiprocessing",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Programming"
      ],
      "notes": "Performance"
    },
    {
      "name": "Docker",
      "years": 5,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "DevOps"
      ],
      "notes": "Containerization"
    },
    {
      "name": "Git",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Version Control"
      ],
      "notes": ""
    },
    {
      "name": "Airflow",
      "years": 5,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Orchestration"
      ],
      "notes": "Data-engineering"
    },
    {
      "name": "Hive/Hadoop",
      "years": 7,
      "proficiency": "Advanced",
      "last_used": "2025",
      "categories": [
        "Big Data"
      ],
      "notes": ""
    },
    {
      "name": "Linux/Unix",
      "years": 20,
      "proficiency": "Expert",
      "last_used": "2025",
      "categories": [
        "OS"
      ],
      "notes": "HPUX, SunOS, Red Hat, infrastructure"
    },
    {
      "name": "OCCI / OCI",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2010",
      "categories": [
        "Databases"
      ],
      "notes": "Oracle"
    },
    {
      "name": "WebLogic / WebSphere",
      "years": 10,
      "proficiency": "Advanced",
      "last_used": "2011",
      "categories": [
        "Application Servers"
      ],
      "notes": ""
    },
    {
      "name": "VB6 / VC++",
      "years": 5,
      "proficiency": "Intermediate",
      "last_used": "2001",
      "categories": [
        "Programming"
      ],
      "notes": "Legacy"
    }
  ],
  "experience": [
    {
      "company": "CITI",
      "title": "Senior Capacity & Data Engineer",
      "start_date": "2017-11",
      "end_date": "2025-12",
      "bullets": [
        "Architected automated ETL pipelines using Python and Pandas to ingest telemetry data from 6,000+ endpoints, enhancing data analysis and operational efficiency.",
        "Developed machine learning forecasting models with Prophet and scikit-learn to predict infrastructure bottlenecks six months ahead, supporting strategic planning.",
        "Designed optimized Oracle schemas for historical data retention, enabling accurate seasonal risk forecasting and system architecture improvements.",
        "Integrated disparate data feeds into unified Oracle reporting systems, creating executive dashboards for actionable business intelligence.",
        "Utilized SQL for data mining to identify underutilized infrastructure, driving hardware consolidation and significant cost savings.",
        "Automated reporting workflows with Python scripts, streamlining process improvement and operational reviews."
      ]
    },
    {
      "company": "G6 Hospitality LLC",
      "title": "Performance Engineer",
      "start_date": "2017-03",
      "end_date": "2017-11",
      "bullets": [
        "Managed Dynatrace AppMon/Synthetics for critical systems, ensuring robust system architecture and performance monitoring.",
        "Led 'FAST' project to data-mine real-user performance metrics, providing recommendations for system optimization and process improvement.",
        "Upgraded Dynatrace from 6.5 to 7.0, implemented TLS1.2 security, and supported cloud migration to AWS for enhanced infrastructure.",
        "Developed dashboards for end-to-end functionality, delivering before/after metrics to support operational reviews.",
        "Analyzed system bottlenecks using data analysis techniques and suggested performance enhancements for workflow optimization.",
        "Integrated Performance Center with Dynatrace for comprehensive monitoring and data-driven insights."
      ]
    },
    {
      "company": "HCL / Entergy",
      "title": "APM Consultant",
      "start_date": "2017-01",
      "end_date": "2017-03",
      "bullets": [
        "Supported enterprise CA APM, CEM, and ADA for utility systems, ensuring reliable performance monitoring.",
        "Managed and supported monitoring solutions to maintain system architecture integrity and operational efficiency."
      ],
      "exclude_from_resume": true
    },
    {
      "company": "CA Technologies (various clients) & Enterprise Iron (TIAA-CREF)",
      "title": "Senior Consultant / SME for CA APM",
      "start_date": "2011",
      "end_date": "2016",
      "bullets": [
        "Led large-scale CA APM implementations and upgrades (9.1 to 10.1), managing 4,000–6,000 agents for robust system architecture.",
        "Designed custom Management Modules, dashboards, and alerts using Perl/Ksh scripts for data extraction and operational reviews.",
        "Provided sizing recommendations and Golden Images, enhancing infrastructure development and process improvement.",
        "Collaborated with IT teams to troubleshoot performance issues in J2EE/.NET environments, ensuring workflow optimization.",
        "Trained client teams on APM solutions, fostering best practices in technical infrastructure and system monitoring.",
        "Analyzed and resolved performance bottlenecks, delivering actionable insights for business intelligence."
      ]
    },
    {
      "company": "AT&T",
      "title": "Performance Test Engineer",
      "start_date": "2010-08",
      "end_date": "2011-07",
      "bullets": [
        "Analyzed J2EE telecom applications for load and break points, documenting key metrics like JDBC, threads, and memory for system architecture.",
        "Installed JMX, Thread Dumps, and Wily Introscope to enhance performance monitoring and data analysis.",
        "Created automation scripts to streamline testing processes, supporting workflow optimization.",
        "Identified resource bottlenecks through detailed data analysis, contributing to operational efficiency."
      ]
    },
    {
      "company": "Sabre",
      "title": "Senior Systems & Data Migration Engineer",
      "start_date": "2008-05",
      "end_date": "2012",
      "bullets": [
        "Led migration of 200+ MySQL nodes to a 6-node Oracle RAC cluster for a high-throughput shopping engine, optimizing system architecture.",
        "Optimized C++/OCCI transaction processing, reducing hardware footprint by 95% while maintaining sub-second latency.",
        "Built CPPUNIT testing framework to automate conversion processes, enhancing workflow optimization.",
        "Utilized data analysis to ensure performance metrics met business requirements during migration.",
        "Collaborated with technical teams to design scalable infrastructure for high-performance systems.",
        "Provided technical leadership in refactoring database systems for improved operational efficiency."
      ]
    },
    {
      "company": "Computer Science Corporation (CSC)",
      "title": "Architect/Developer (IRS CADE Project)",
      "start_date": "2007-10",
      "end_date": "2008-05",
      "bullets": [
        "Performed UML-based unit design for CICS/MQSeries/XML/DB2 systems, contributing to robust system architecture.",
        "Developed modules for IRS modernization, ensuring alignment with technical requirements.",
        "Collaborated on messaging architecture using VC++ and DB2 for operational efficiency."
      ]
    },
    {
      "company": "Corpus Inc. / Sprint (AMDOCS projects)",
      "title": "Developer / Support Engineer (Billing, Interfaces, CSM/PRMS)",
      "start_date": "2001",
      "end_date": "2007",
      "bullets": [
        "Developed high-availability multithreaded C++ interfaces using POSIX, sockets, and Marconi APIs for robust system architecture.",
        "Enhanced billing performance with C/C++/Pro*C/PL/SQL, achieving 75% memory reduction and 10x database performance.",
        "Automated system administration for WebLogic/WebSphere using Korn Shell scripts, supporting workflow optimization.",
        "Designed interfaces with UML in Rational Rose, incorporating class/sequence diagrams for process improvement.",
        "Troubleshot Enabler/CSM/EMS modules, ensuring operational reliability and efficiency.",
        "Utilized SQL for database queries and reporting, driving actionable insights for business intelligence."
      ]
    },
    {
      "company": "Simplex International - Canada",
      "title": "Developer",
      "start_date": "1999",
      "end_date": "2001",
      "bullets": [
        "Developed time/attendance interfaces using VB6/VC++ to support operational systems."
      ]
    },
    {
      "company": "Humber College",
      "title": "Lab Support",
      "start_date": "1996-09",
      "end_date": "1999-04",
      "bullets": [
        "Maintained and troubleshot Linux/Windows systems, performing various admin tasks for operational support.",
        "Ensured system reliability through proactive monitoring and technical problem-solving."
      ]
    }
  ],
  "education": [
    {
      "degree": "High Diploma / Post-Graduate Diploma in Computer Engineering Technology / Computer Science",
      "institution": "Humber College",
      "location": "Toronto, Canada",
      "dates": "Not specified"
    },
    {
      "degree": "Bachelor of Science in Civil Engineering",
      "institution": "Zagazig University",
      "location": "Egypt / Cairo, Egypt",
      "dates": "Not specified"
    }
  ],
  "projects": [
    {
      "name": "Serverless Lakehouse Platform (AWS)",
      "description": "Designed a full serverless data platform using S3, Glue, Athena, and Bedrock. Built a Text-to-SQL GenAI agent with Claude 3 Sonnet. Resolved small file issues using Snappy and Parquet compression. Optimized ETL and data access for enterprise-scale operations.",
      "technologies": [
        "AWS Glue",
        "Athena",
        "Bedrock (GenAI)",
        "S3",
        "PySpark"
      ],
      "timeframe": "Recent"
    },
    {
      "name": "HorizonScale — AI Capacity Forecasting Engine",
      "description": "Replaced legacy manual processes with a parallel generator-based pipeline, reducing forecasting cycles by 90%. Developed an interactive Streamlit dashboard for real-time capacity insights and 'High Trust' utilization scores. Created a modern agentic pipeline for banking-scale telemetry. Features comprehensive documentation, API guides, and performance benchmarks.",
      "technologies": [
        "Python",
        "Prophet",
        "Streamlit",
        "PySpark",
        "Multiprocessing",
        "Spark",
        "Machine Learning",
        "Data Pipelines",
        "API Integration",
        "Performance Benchmarking",
        "Testing and Validation",
        "AI Reasoning",
        "RAG (Retrieval-Augmented Generation)"
      ],
      "repo": "https://github.com/seanlgirgis/HorizonStudy",
      "documentation": [
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/README.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/API_AND_INTEGRATION_GUIDE.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/FUTURE_ROADMAP.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/OPERATIONAL_RUNBOOK.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/PERFORMANCE_BENCHMARK_REPORT.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/TESTING_AND_VALIDATION_STRATEGY.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/TREND_TO_HORIZONSCALE_EVOLUTION.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/lessons_learnt.md",
        "https://github.com/seanlgirgis/HorizonStudy/blob/main/Docs/AI_REASONING_AND_RAG_SPEC.md"
      ],
      "code": "https://github.com/seanlgirgis/HorizonStudy/tree/main/src/HorizonScale",
      "additional_docs": [
        "https://github.com/seanlgirgis/HorizonStudy/tree/main/Docs/lib",
        "https://github.com/seanlgirgis/HorizonStudy/tree/main/Docs/pipeline",
        "https://github.com/seanlgirgis/HorizonStudy/tree/main/Docs/synthetic"
      ],
      "timeframe": "Recent"
    },
    {
      "name": "FAST Project",
      "description": "Conducted data mining of user performance metrics to optimize critical money-generating systems. Utilized Dynatrace for comprehensive analysis and actionable insights.",
      "technologies": [
        "Dynatrace",
        "Data Mining"
      ],
      "timeframe": "2017"
    }
  ]
}