# Tailored Resume Preview

**Sean Luka Girgis**  
Senior Data Engineer | Capacity Planning & AI-Driven Infrastructure Optimization  
214-315-2190 | seanlgirgis@gmail.com  
[LinkedIn](https://www.linkedin.com/in/sean-girgis-43bb1b5/) | [GitHub](https://github.com/seanlgirgis) | [Portfolio](https://seanlgirgis.github.io)  

## Professional Summary
Senior Data Engineer with over 20 years of enterprise experience, specializing in data analysis, system architecture, and technical problem-solving with proficiency in SQL, Python, Java, and C++. Adept at building scalable data infrastructure and optimizing workflows through data engineering and business intelligence practices. Experienced in leveraging relational databases and data science techniques to drive actionable insights and process improvements. Passionate about translating business goals into technical solutions, with a strong focus on operational reviews and product activation systems. Eager to contribute to YouTube’s mission of empowering creators and partners within Google’s innovative ecosystem by driving strategic initiatives for the partner ecosystem.

## Professional Experience
### Senior Capacity & Data Engineer at CITI
2017-11 – 2025-12
- Architected automated ETL pipelines using Python and Pandas to ingest telemetry data from 6,000+ endpoints, enhancing data analysis and operational efficiency.
- Developed machine learning forecasting models with Prophet and scikit-learn to predict infrastructure bottlenecks six months ahead, supporting strategic planning.
- Designed optimized Oracle schemas for historical data retention, enabling accurate seasonal risk forecasting and system architecture improvements.
- Integrated disparate data feeds into unified Oracle reporting systems, creating executive dashboards for actionable business intelligence.
- Utilized SQL for data mining to identify underutilized infrastructure, driving hardware consolidation and significant cost savings.
- Automated reporting workflows with Python scripts, streamlining process improvement and operational reviews.

### Performance Engineer at G6 Hospitality LLC
2017-03 – 2017-11
- Managed Dynatrace AppMon/Synthetics for critical systems, ensuring robust system architecture and performance monitoring.
- Led 'FAST' project to data-mine real-user performance metrics, providing recommendations for system optimization and process improvement.
- Upgraded Dynatrace from 6.5 to 7.0, implemented TLS1.2 security, and supported cloud migration to AWS for enhanced infrastructure.
- Developed dashboards for end-to-end functionality, delivering before/after metrics to support operational reviews.
- Analyzed system bottlenecks using data analysis techniques and suggested performance enhancements for workflow optimization.
- Integrated Performance Center with Dynatrace for comprehensive monitoring and data-driven insights.

### Senior Consultant / SME for CA APM at CA Technologies (various clients) & Enterprise Iron (TIAA-CREF)
2011 – 2016
- Led large-scale CA APM implementations and upgrades (9.1 to 10.1), managing 4,000–6,000 agents for robust system architecture.
- Designed custom Management Modules, dashboards, and alerts using Perl/Ksh scripts for data extraction and operational reviews.
- Provided sizing recommendations and Golden Images, enhancing infrastructure development and process improvement.
- Collaborated with IT teams to troubleshoot performance issues in J2EE/.NET environments, ensuring workflow optimization.
- Trained client teams on APM solutions, fostering best practices in technical infrastructure and system monitoring.
- Analyzed and resolved performance bottlenecks, delivering actionable insights for business intelligence.

### Performance Test Engineer at AT&T
2010-08 – 2011-07
- Analyzed J2EE telecom applications for load and break points, documenting key metrics like JDBC, threads, and memory for system architecture.
- Installed JMX, Thread Dumps, and Wily Introscope to enhance performance monitoring and data analysis.
- Created automation scripts to streamline testing processes, supporting workflow optimization.
- Identified resource bottlenecks through detailed data analysis, contributing to operational efficiency.

### Senior Systems & Data Migration Engineer at Sabre
2008-05 – 2012
- Led migration of 200+ MySQL nodes to a 6-node Oracle RAC cluster for a high-throughput shopping engine, optimizing system architecture.
- Optimized C++/OCCI transaction processing, reducing hardware footprint by 95% while maintaining sub-second latency.
- Built CPPUNIT testing framework to automate conversion processes, enhancing workflow optimization.
- Utilized data analysis to ensure performance metrics met business requirements during migration.
- Collaborated with technical teams to design scalable infrastructure for high-performance systems.
- Provided technical leadership in refactoring database systems for improved operational efficiency.

## Education
**High Diploma / Post-Graduate Diploma in Computer Engineering Technology / Computer Science**  
Humber College, Toronto, Canada

**Bachelor of Science in Civil Engineering**  
Zagazig University, Egypt / Cairo, Egypt

## Skills
SQL / Oracle, Python, Java, C++, ETL Design & Optimization, Data Warehousing, Pandas, scikit-learn, AWS, PySpark, Prophet / Time-Series Forecasting, Capacity Planning / Forecasting, GenAI / LLM Agents, Streamlit, PL/SQL, Perl, Ksh / Korn Shell Scripting, Dynatrace (AppMon + Synthetics), CA APM / Introscope, BMC TrueSight / TSCO, Oracle RAC, Multiprocessing, Docker, Git, Airflow, Hive/Hadoop, Linux/Unix, OCCI / OCI, WebLogic / WebSphere, VB6 / VC++

## Flagship Projects
### Serverless Lakehouse Platform (AWS)
Designed a full serverless data platform using S3, Glue, Athena, and Bedrock. Built a Text-to-SQL GenAI agent with Claude 3 Sonnet. Resolved small file issues using Snappy and Parquet compression. Optimized ETL and data access for enterprise-scale operations.
**Technologies:** AWS Glue, Athena, Bedrock (GenAI), S3, PySpark

### HorizonScale — AI Capacity Forecasting Engine
Replaced legacy manual processes with a parallel generator-based pipeline, reducing forecasting cycles by 90%. Developed an interactive Streamlit dashboard for real-time capacity insights and 'High Trust' utilization scores. Created a modern agentic pipeline for banking-scale telemetry. Features comprehensive documentation, API guides, and performance benchmarks.
**Technologies:** Python, Prophet, Streamlit, PySpark, Multiprocessing, Spark, Machine Learning, Data Pipelines, API Integration, Performance Benchmarking, Testing and Validation, AI Reasoning, RAG (Retrieval-Augmented Generation)
**Repo:** [github.com/seanlgirgis/HorizonStudy](https://github.com/seanlgirgis/HorizonStudy)

### FAST Project
Conducted data mining of user performance metrics to optimize critical money-generating systems. Utilized Dynatrace for comprehensive analysis and actionable insights.
**Technologies:** Dynatrace, Data Mining

