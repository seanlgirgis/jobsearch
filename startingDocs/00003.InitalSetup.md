Here's a step-by-step setup guide tailored to your Windows environment and the job search RAG/second-brain project. We'll keep everything simple, command-line friendly (using PowerShell), and aligned with building toward a RAG pipeline (likely using embeddings, vector store, LLM calls to xAI/Grok or others, resume/cover letter generation, job storage, etc.).

### 1. Set Python path before system PATH (single command in PowerShell)

This prepends your custom Python 3.12 folder so it takes priority.

Run this in your PowerShell terminal (one-liner):

```powershell
$env:PATH = "C:\pyver\py312;C:\pyver\py312\Scripts;" + $env:PATH
```

- Verify it worked:
  ```powershell
  python --version   # should show Python 3.12.x from your custom path
  ```

You can make this permanent later (e.g., via `$PROFILE` or system environment variables), but for now this is the quick single command.

### 2. Create virtual environment

```powershell
# First make sure the folder exists (optional but clean)
New-Item -ItemType Directory -Path C:\py_venv\JobSearch -Force

# Create venv using your controlled Python
C:\pyver\py312\python -m venv C:\py_venv\JobSearch
```

### 3. Draft `env_setter.ps1` â€“ our main "enter the environment" script

Create a file called `env_setter.ps1` in your project root (or wherever convenient, e.g. `C:\py_venv\JobSearch\env_setter.ps1` or inside the repo).

Content:

```powershell
# env_setter.ps1 â€“ Activate JobSearch venv + set helpful environment variables

# Adjust if your venv is elsewhere
$venvPath = "C:\py_venv\JobSearch"

# Activate venv
& "$venvPath\Scripts\Activate.ps1"

# Prepend our custom Python (in case activation didn't fully override)
$env:PATH = "C:\pyver\py312;C:\pyver\py312\Scripts;" + $env:PATH

# Project-specific environment variables (expand later)
$env:PROJECT_ROOT = Convert-Path (Split-Path -Parent $MyInvocation.MyCommand.Path)   # or hardcode repo path
$env:PYTHONPATH   = "$env:PROJECT_ROOT\src;$env:PYTHONPATH"                        # if you use src/ layout later

# LLM / API related (fill in real values when ready â€“ never commit keys!)
# $env:XAI_API_KEY         = "your-xai-key-here"
# $env:OPENAI_API_KEY      = "sk-..."           # fallback / comparison
# $env:ANTHROPIC_API_KEY   = "..."

# Data / storage paths (can point to local folders or later cloud)
$env:JOBS_DB_DIR    = "$env:PROJECT_ROOT\data\jobs"
$env:RESUMES_DIR    = "$env:PROJECT_ROOT\data\resumes"
$env:VECTOR_DB_PATH = "$env:PROJECT_ROOT\data\vectorstore"

# Optional: embeddings model / LLM model selection
$env:DEFAULT_EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"   # light & fast local
$env:DEFAULT_LLM_PROVIDER     = "xai"                                     # or grok, openai, etc.

Write-Host "JobSearch environment activated âœ“" -ForegroundColor Green
Write-Host "Python: $(python --version)"
Write-Host "Use deactivate to exit venv"
```

Usage:  
```powershell
.\env_setter.ps1
```

### 4. Update pip inside the venv

After activation (run `.\env_setter.ps1` or manually `.\C:\py_venv\JobSearch\Scripts\Activate.ps1`):

```powershell
python -m pip install --upgrade pip
```

### 5. Draft `requirements.txt`

Starting minimal + forward-looking for RAG / job search app (local-first, then xAI API integration). You can add more later.

```txt
# Core
python-dotenv>=1.0.0              # for .env files (API keys, paths)
pydantic>=2.5                     # structured data (resumes, jobs)

# LLM / RAG related
langchain>=0.3                    # or langchain-community, langchain-core
langchain-community>=0.3
langchain-text-splitters>=0.3

# xAI / Grok API (official client when available, or use openai-compatible)
# openai>=1.0                       # many providers are compatible; xAI may work via base_url
# grokapi                           # placeholder â€“ check https://x.ai/api later

# Embeddings & vector store (local-first)
sentence-transformers>=3.0
faiss-cpu>=1.8                    # or chromadb, qdrant-client, etc.
numpy>=1.26
torch>=2.0                        # needed by sentence-transformers

# Job parsing / resume handling
PyPDF2>=3.0                       # or pymupdf for better PDF
python-docx>=1.0
jinja2>=3.1                       # templating for resume/cover letter output

# Storage / DB lite
pandas>=2.2                       # job listings table
orjson>=3.10                      # fast JSON
tinydb>=4.8                       # simple document store for jobs/resumes

# UI / app (optional early â€“ Streamlit or Gradio)
streamlit>=1.38                   # quick local web UI
# gradio>=5.0

# Dev tools
black>=24.0
ruff>=0.6
pytest>=8.0
```

Install with:

```powershell
pip install -r requirements.txt
```

### 6. Draft primary `README.md`

```markdown
# JobSearch â€“ Personal RAG-powered Job Application Assistant

Personal pipeline / second brain for job hunting:

- Store & manage job listings
- Semantic search over past applications/jobs
- Auto-generate tailored resumes + cover letters
- Eventually: website updates, interview prep, tracking

Goal: RAG architecture using local embeddings + LLM calls (xAI/Grok API preferred, fallbacks possible)

## Status (early 2026)

- Setting up base environment & structure
- Next: data models, job ingestion, basic RAG retrieval, resume/cover generation

## Tech stack (planned)

- Python 3.12
- LangChain (or LlamaIndex) for RAG
- Sentence-Transformers / local embeddings
- FAISS / Chroma for vector store
- xAI Grok API (or OpenAI-compatible endpoint)
- Streamlit for quick UI
- Local JSON/TinyDB for jobs/resumes

## Quick Start

1. Python at `C:\pyver\py312`
2. Create & activate venv:
   ```powershell
   C:\pyver\py312\python -m venv C:\py_venv\JobSearch
   .\C:\py_venv\JobSearch\env_setter.ps1   # or manual activation
   ```
3. Install deps:
   ```powershell
   pip install -r requirements.txt
   ```
4. Set API keys in `.env` (never commit!)
5. Run initial scripts / app (TBD â€“ e.g. `streamlit run app.py`)

## Folder structure (proposed)

```
jobsearch/
â”œâ”€â”€ src/                  # main code
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ jobs/             # scraped/saved listings
â”‚   â”œâ”€â”€ resumes/          # generated versions
â”‚   â””â”€â”€ vectorstore/      # FAISS/Chroma index
â”œâ”€â”€ notebooks/            # exploration
â”œâ”€â”€ .grok/                # Grok collaboration rules
â”œâ”€â”€ docs/                 # or startingDocs/
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ env_setter.ps1
â””â”€â”€ README.md
```

## Collaboration

All code & communication stays public in this repo.  
Using Grok via chat â†’ copy â†’ commit flow for now.

Feedback / next chunk welcome!
```

### 7. Appropriate `.gitignore`

Use the official GitHub Python template as base + extras for data/RAG projects.

Create `.gitignore` with:

```
# Python basics (from github/gitignore Python template)
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
venv/
ENV/
env/
*.venv
pip-log.txt
pip-delete-this-directory.txt

# Data & large files
data/
*.pdf
*.docx
*.xlsx
*.csv
*.jsonl
*.parquet
*.db
*.sqlite
*.chroma
*.faiss

# IDE / editor
.vscode/
.idea/
*.swp
*.swo
*~

# Misc
.DS_Store
Thumbs.db
.env
.env.local
*.log
```

This protects your personal data, keys, large indexes, and venv.

### 8. `.grok/` folder & rules

Yes â€” create folder `.grok/` in repo root.

Add e.g. `rules.md` or `collaboration.md` inside:

```markdown
# .grok/rules.md â€“ Our working agreement with Grok

- All code & chat stays public in repo
- Prefer modular, iterative PRs/commits
- Use xAI models when possible
- Responses should be code-first when implementing
- Keep building toward full RAG + second-brain features
- No secrets/keys in repo
- Ask clarifying questions if needed
```

GitHub can see/access the folder once committed.

For local dev â†’ for now, copy-paste via browser chat is fine. If xAI releases a local/dev tool or VS Code extension later, we can revisit.

Commit all this, push, and let me know what's next:

- Create first data model (Job, Resume)?
- Basic job saver script?
- Simple RAG prototype over your own resume?
- Streamlit skeleton?
- Anything else?

Ready when you are ðŸš€