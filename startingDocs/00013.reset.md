Thank you for the clear feedback — I agree we've made solid progress, and this realignment will tighten things up without losing momentum. I'll prioritize documenting my work in the .grok files (constitution.md, decisions.md, rules.md) as we go, starting with updates based on this conversation. For instance, I'll propose additions like a new rule against full LLM outsourcing for resumes/covers to avoid inconsistencies, and a decision to enforce a source-of-truth database for user profile data.

To kick this off properly from the "real beginning," let's establish the user_guide directory structure conceptually here (we can commit it to the repo later). I'll draft the initial content for user_guide/v0/ (since we're in iteration 0: POC using scripts). This will include a high-level usage guide, per-script breakdowns (with input, process, outsourcing notes), and how-to instructions. As we iterate, we can version it up (e.g., v1.0 for more integrated flows).

### Proposed Directory Structure for user_guide/
- **user_guide/**
  - **v0/** (Proof-of-Concept: Script-based workflow)
    - README.md (Overall usage guide and quick-start)
    - script_guides/ (Subdir for per-script docs)
      - profile_source_of_truth.md
      - job_intake.md
      - job_scoring.md
      - job_decision.md
      - resume_intermediate.md
      - resume_generation.md
      - cover_intermediate.md
      - cover_generation.md
      - job_tracking.md
  - **v1.0/** (Future: Basic integration, e.g., chained scripts or simple CLI)
  - **v2/** (Future: Full app, e.g., Streamlit UI with RAG)

I'll draft the v0 README.md content below as a starting point. We can refine it together and commit to the repo.

---

#### user_guide/v0/README.md (Draft)

# JobSearch Pipeline User Guide - v0 (POC: Script-Based)

## Overview
This is the proof-of-concept iteration of the JobSearch pipeline. Everything runs via individual Python scripts (no integrated app yet). The focus is on modular, auditable steps to avoid LLM over-reliance and ensure consistency (e.g., no date overlaps in resumes).

Key Principles (from .grok/Constitution.md):
- Modular: Each step is a standalone script.
- Auditable: Intermediate files for user review/editing.
- Consistent: All generations reference a "source of truth" database for your profile (e.g., job dates, field names like "portfolio" vs "website").
- No Full LLM Outsourcing: LLMs assist only in drafting intermediates; final generation is script-based (no LLM creativity).
- Public: All code/comms in https://github.com/seanlgirgis/jobsearch.git.

## Quick-Start Workflow
1. **Setup Source of Truth**: Run the profile setup script once to build your personal job database (JSON/YAML file).
2. **Intake a Job**: Provide a job description file; script stores it permanently.
3. **Score the Job**: Run scoring script for fit assessment.
4. **Decide on Job**: Accept/Reject/Hold with notes; updates job status.
5. **Generate Resume Intermediate**: LLM drafts a tailored intermediate (checked against source of truth).
6. **Review/Edit Resume Intermediate**: You manually review/edit (sanity check dates, etc.).
7. **Generate Final Resume**: Script formats from intermediate (no LLM).
8. **Generate Cover Intermediate**: Similar to resume, LLM drafts with source of truth checks.
9. **Review/Edit Cover Intermediate**: You review/edit.
10. **Generate Final Cover**: Script formats from intermediate.
11. **Track Application**: Update job status with events (e.g., "applied").

Run scripts from the root dir: `python scripts/<script_name>.py --input <file> --output <file>`. See per-script guides in script_guides/ for details.

## Source of Truth
All scripts reference a single file (e.g., `data/source_of_truth.json`) for your immutable profile data. This prevents errors like overlapping dates. Build it once via the profile script.

## Per-Script Guides
Detailed in script_guides/ subdir. Each includes:
- **Input**: Required files/args.
- **Process**: Step-by-step what happens.
- **Outsourcing**: Any LLM calls (limited, with prompts enforcing source of truth).

---

Now, for the per-script guides in user_guide/v0/script_guides/. I'll draft stubs for each based on your outlined steps (A-G). These assume script names like `profile_source_of_truth.py`, etc. — we can implement/code them next. Each guide explains usage, and I'll ensure the scripts themselves are heavily documented (docstrings, comments) when we build them.

#### profile_source_of_truth.md (For Step A: One-Time Source of Truth)
- **Purpose**: One-time setup to unify your job history into a structured JSON file (e.g., `data/source_of_truth.json`). Includes dates, roles, skills, field names (e.g., standardize "portfolio" vs "website"). Studies existing intake files, unifies data, archives duplicates/unneeded.
- **Input**: User-provided profile data (e.g., via JSON/CSV of jobs, or pasted text). Existing intake files in `intake/` for unification.
- **Process**:
  1. Parse user input (jobs, dates, etc.).
  2. Validate: Check for date overlaps (e.g., end_date < next_start_date).
  3. Standardize fields (e.g., map "site" to "website").
  4. Add lookups (e.g., skills list, achievements).
  5. Output JSON; archive old intakes if redundant.
- **Outsourcing**: Minimal — optional LLM for parsing unstructured text into structure, but with strict prompt: "Extract exact dates/roles without changes; flag overlaps."
- **Usage**: `python scripts/profile_source_of_truth.py --profile_input my_jobs.json --output data/source_of_truth.json`. Run once; update manually if profile changes.
- **User Guide Tip**: After running, review the JSON for accuracy. This file is referenced in all generation steps.

#### job_intake.md (For Step B: Job Intake)
- **Purpose**: Store a new job description permanently in `intake/` (e.g., as JSON). Keeps original user input forever.
- **Input**: Job file (text/JSON from user).
- **Process**:
  1. Validate format.
  2. Assign unique ID.
  3. Save to `intake/<id>.json`.
- **Outsourcing**: None.
- **Usage**: `python scripts/job_intake.py --job_file new_job.txt --id optional_custom_id`.

#### job_scoring.md (For Step B: Scoring)
- **Purpose**: Score job fit against your source of truth (e.g., skills match).
- **Input**: Job ID from intake.
- **Process**:
  1. Load job and source of truth.
  2. Compute score (e.g., keyword match, simple ML if needed).
  3. Output score file.
- **Outsourcing**: Optional LLM for semantic matching, but script-driven.
- **Usage**: `python scripts/job_scoring.py --job_id <id> --output scores/<id>.json`.

#### job_decision.md (For Step C: Acceptance/Rejection/Hold)
- **Purpose**: Process user decision on job (accept/reject/hold + message). Updates job status in a tracking file (e.g., `data/jobs_tracker.json`).
- **Input**: Job ID, decision (accept/reject/hold), message.
- **Process**:
  1. Load tracker.
  2. Add/update entry.
  3. Save.
- **Outsourcing**: None.
- **Usage**: `python scripts/job_decision.py --job_id <id> --decision accept --message "Good fit"`.

#### resume_intermediate.md (For Step D: Resume Intermediate)
- **Purpose**: Use LLM to draft a tailored resume intermediate (JSON/MD), enforcing source of truth for dates/fields. Sanity check dates.
- **Input**: Job ID, source of truth.
- **Process**:
  1. Load job and truth.
  2. Prompt LLM: "Tailor resume sections using exact dates/roles from truth; no creativity; flag inconsistencies."
  3. Validate output: Check dates vs truth.
  4. Output intermediate: `intermediates/resume_<id>.json`.
- **Outsourcing**: LLM (Grok/xAI) for drafting, with strict truth-binding prompt.
- **Usage**: `python scripts/resume_intermediate.py --job_id <id>`.

#### resume_generation.md (For Step F: Resume Generation)
- **Purpose**: Generate final resume formats from reviewed intermediate (no LLM).
- **Input**: Edited intermediate file.
- **Process**:
  1. Load intermediate.
  2. Apply templates (e.g., MD to PDF via pandoc).
  3. Output formats: PDF, DOCX, etc.
- **Outsourcing**: None.
- **Usage**: `python scripts/resume_generation.py --intermediate intermediates/resume_<id>.json --formats pdf,docx`.

(Similar drafts for cover_intermediate.md, cover_generation.md — mirroring resume but for covers.)

#### job_tracking.md (For Step G: Track Events)
- **Purpose**: Update job tracker with application events (e.g., "resume generated", "applied").
- **Input**: Job ID, event type, details.
- **Process**: Append to `data/jobs_tracker.json`.
- **Outsourcing**: None.
- **Usage**: `python scripts/job_tracking.py --job_id <id> --event "applied" --details "Submitted via LinkedIn"`.

---

This draft covers the user/usage guides. To implement:
- I need your profile data to build the source of truth (Step A). Can you provide a copy/paste or file of your job history (roles, dates, skills, etc.)? E.g., in JSON like: [{"role": "Engineer", "start": "2010-01", "end": "2012-06", ...}].
- For existing scripts (e.g., any from prior work like job scoring), please provide copies here or links to specific files in the repo. I'll analyze them for documentation gaps, ensure they align (e.g., add source-of-truth refs), and update .grok accordingly.
- On memory: I'll propose adding a .grok/memory.md for convo summaries (e.g., "2026-02-05: Aligned on source-of-truth DB; no LLM creativity."). This can be fed back into prompts for consistency.

What's your feedback on these drafts? Any tweaks before we code the first script (e.g., profile_source_of_truth.py)? Or priority on which to implement first?